{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207e38d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17448e73",
   "metadata": {},
   "source": [
    "#### HTML의 구조  및 태그\n",
    "- 구조\n",
    " - \\<!Doctype html> : HTML5 문서를 선언하는 구문\n",
    " - \\<html></html> : HTML 문서의 시작과 끝\n",
    " - \\<head></head> : CSS, JavaScript, meta, title 정보들을 설정\n",
    " - \\<body></body> : 실제 홈페이지 화면을 나타내는 부분\n",
    "\n",
    "- 요소 구조\n",
    " - HTML 요소는 여러 속성들을 가질 수 있으며 속성들은 해당 요소에 대한 추가 정보를 제공\n",
    " - 시작 태그\\(< >)로 시작해서 종료 태그(</>)로 끝남\n",
    " - 요소 안에 다른 요소를 작성할 수 있음 \n",
    " <img src = './dataset/html요소구조.jpg' STYLE = 'width:500px;'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a446b5",
   "metadata": {},
   "source": [
    "#### HTML 태그\n",
    "\n",
    "- p 태그를 이용하여 문단 작성\n",
    "- h 태그를 이용하여 폰트 크기 설정\n",
    "- ul(unordered list)과 ol(ordered list) 태그로 리스트 작성, 리스트 각각의 요소는 li(항목 나열) 태그로 표시  \n",
    "- table 태그는 thead, tbody를 가질 수 있으며 표를 표현 : tr 행, th(가운데 정렬,굵은 글씨체),td 각 행의 컬럼\n",
    "- input 태그와 button 태그 : 데이터를 넣는 폼과 페이지 조작 버튼 생성\n",
    "- select # select 태그로 선택 리스트 생성\n",
    "- a 태그로 다른 페이지로 이동. 상대경로(내가 있는 경로부터의 경로), 절대경로(항상 같은 url)\n",
    "- img 태그로 이미지 포함 : src(이미지 붙임), alt(이미지 대체)\n",
    "- span 태그로 p태그 처럼 글을 추가. span 태그는 옆으로 나열. br 태그 사용하여 p 태그처럼 사용\n",
    "- div 태그는 화면 레이아웃을 잡는 역할 : 하위 태그들의 영역을 잡아줌\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9e587c",
   "metadata": {},
   "source": [
    "#### CSS\n",
    "- CSS로 웹 사이트를 꾸며주기 위해 해당 태그에 접근하는 방식을 크롤러에서도 사용.\n",
    "- selector : CSS로 꾸미기 위해 특정 요소에 접근하는 것을 셀렉터라고 함.\n",
    "- html 파일을 만들었다면 각각의 태그에 다르게 css 를 설정 할 것입니다. 이 때, 어느 요소에 스타일을 적용할지 알려주는 방식이 바로 css 선택자 입니다.\n",
    "- 태그를 이용하여 접근하면 태그는 전부 CSS 효과가 적용\n",
    "- class를 이용하면 원하는 요소만 CSS 효과 적용할 수 있고 원하는 요소만 수집할 수 있음.\n",
    "- id는 class와 다르게 id값이 고유해야 함(id는 한페이지에 하나만 존재해야 함)\n",
    "- 부모 태그와 자식 태그를 나열하여 복잡한 셀렉터를 생성\n",
    "\n",
    "\n",
    "#### CSS 선택자 이해\n",
    "\n",
    "https://ssungkang.tistory.com/entry/css-css-%EC%84%A0%ED%83%9D%EC%9E%90selector-%EC%9D%98-%EC%A2%85%EB%A5%98%EC%99%80-%EC%98%88%EC%8B%9C\n",
    "https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors\n",
    "https://www.nextree.co.kr/p8468/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27337753",
   "metadata": {},
   "source": [
    "#### JavaScript\n",
    "- 웹 사이트의 기능을 넣어줌. script 태그를 이용하여 작성. head or body 하단에 위치\n",
    "- js를 이용하여 HTML 코드를 생성. 크롤러로 분석하기 가장 어려운 부분임\n",
    "- DOM(Document Object Model)이란 HTML을 시각적으로 쉽게 표현하기 위해 만든 객체로 크롤러 만들 때 중요\n",
    "- 데이터를 수집하기 위해 DOM을 이용해 데이터에 접근한 후 해당 데이터 수집\n",
    "- 웹 브라우저는 HTML 코드를 가져온 후 JavaScript를 실행시킨 결과를 보여줌\n",
    "- 소스 보기 페이지에 수집하고자 하는 요소가 없다면 네트워크 탭을 이용, 서버에서 데이터를 받아오는 지 확인\n",
    "- 그렇지 않은 경우 셀레니움을 사용하여 해결\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ed476",
   "metadata": {},
   "source": [
    "http://www.tcpschool.com/javascript/js_dom_document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876d2bf8",
   "metadata": {},
   "source": [
    "파이썬을 활용한 데이터 가공\n",
    "\n",
    "- 문자열 자료형(인덱싱) : 시퀀스 자료형으로 인덱스가 있고 인덱스 값으로 접근이 가능함\n",
    "- 파이썬에서 문자열을 쉽게 다룰 수 있도록 제공하는 내장함수\n",
    "    - find: 해당문자가 없으면 -1 반환\n",
    "    - index : 해당문자가 없으면 에러\n",
    "    - strip : 데이터 가공 초기 단계에 불필요한 공백을 지울 때 사용\n",
    "    - replace : 특정 문자를 원하는 내용으로 변경\n",
    "- 정규표현식\n",
    "    - 특정한 규칙을 가진 문자열을 표현하기 위해 사용하는 형식\n",
    "    - 주로 문자열의 검색 및 치환에 활용\n",
    "    - re 모율을 제공\n",
    "    - 규칙을 정의하기 위해 메타 문자를 활욜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7013ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#<g1>은 첫번째 그룹을 의미\n",
    "import re \n",
    "\n",
    "data = \"\"\"\n",
    "park 800905-1049118\n",
    "kim  700905-1059119\n",
    "\"\"\"\n",
    "\n",
    "pat = re.compile(\"(\\d{6})[-]\\d{7}\")\n",
    "print(pat.sub(\"\\g<1>-*******\", data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f371dd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\n",
      "기\n",
      "Abc\n",
      "ABC\n",
      "K-digital training 5기\n"
     ]
    }
   ],
   "source": [
    "# 인덱싱\n",
    "text = \"k-digital training 5기\"\n",
    "text1 = 'abc'\n",
    "print(text[0])\n",
    "print(text[-1])\n",
    "print(text1.capitalize())\n",
    "print(text1.upper())\n",
    "print(text.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41653910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'K-Digital Training 5기'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#[과제]\"K-Digital Training 5기\"를 출력하세요.\n",
    "text = \"k-digital training 5기\"\n",
    "text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99884eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<k-digital training 5기>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"   <k-digital training 5기>   \"\n",
    "text2 = \";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e4fa85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<k-digital training 5기>;'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. <k-digital training 5기>를 출력하세요.\n",
    "text1.strip()+text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eb0bfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<k-digital training 5기>   ;'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. <k-digital training 5기>   ; 를 출력하세요.\n",
    "text1.lstrip()+text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68066c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   <k-digital training 5기>;'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q.    <k-digital training 5기>; 를 출력하세요.\n",
    "text1.rstrip()+text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9715648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '<title>k-digital training 5기</title>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c98b5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div>k-digital training 5기</title>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. text를 아래와 같이 출력하세요.\n",
    "# <div>k-digital training 5기</title>\n",
    "text.replace('<title','<div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3403879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div>k-digital training 5기</div>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. text를 아래와 같이 출력하세요.\n",
    "# <div>k-digital training 5기</div>\n",
    "text.replace('title','div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcf24ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<head>안녕하세요</head>'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규표현식\n",
    "text = ('111<head>안녕하세요</head>22')\n",
    "# <head>안녕하세요</head> 뽑기\n",
    "import re\n",
    "t = re.search('[\\D]+',text)\n",
    "t.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4bd699bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = re.compile('[가-힣]+').search(text)\n",
    "body.group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2136092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '<head>안녕하세요...<title>k-digital training 5기</title> 반갑습니다...</head>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48b9fede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<title>k-digital training 5기</title>'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <title>k-digital training 5기</title>\n",
    "t = re.search('<title>.+</title>',text)\n",
    "t.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "512615e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k-digital training 5기'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-digital training 5기 를 출력하세요\n",
    "body = re.search('<title>(.+)</title>',text)\n",
    "body.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8663af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k-digital training 5기'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = re.sub('<.+?>','',body.group())\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560cdec8",
   "metadata": {},
   "source": [
    "requests 모듈\n",
    "- pip install requests 명령어로 설치\n",
    "- http는 요청과 응답으로 이루어져 있음\n",
    "- 요청\n",
    "    - GET : 정보를 가져오기 위해 요청\n",
    "    - POST : 새로운 정보를 보내기 위해 요청\n",
    "    - PUT : 수정할 정보를 보내기 위해 요청\n",
    "    - DELETE : 정보를 삭제하기 위해 요청\n",
    "- 응답\n",
    "    - 1XX : 요청을 받았고 작업 진행 중\n",
    "    - 2XX : 사용자의 요청이 성공적으로 수행됨\n",
    "    - 3XX : 요청은 완료되었으나 리다이렉션이 필요\n",
    "    - 4XX : 사용자의 요청이 잘못됨\n",
    "    - 5XX : 서버오류가 발생함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c35051cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.11-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\cakd5\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, requests\n",
      "Successfully installed charset-normalizer-2.0.11 idna-3.3 requests-2.27.1 urllib3-1.26.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a3e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "URL = 'http://naver.com'\n",
    "response = requests.get(URL)\n",
    "response.status_code\n",
    "html_data = response.text\n",
    "html_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c71fbc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_data.find('네이버')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "788b37c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네이버 메인에서 다양한 정보'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_data[365:380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4cb4720f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'네이버'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = re.search('[가-힣]+',html_data)\n",
    "t.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "85416626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 만나 보세요\"/> <meta property=\"og:title\" content=\"네이버\"> <meta pr\n"
     ]
    }
   ],
   "source": [
    "html_data.find('<meta property=')\n",
    "print(html_data[390:450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5ca09837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<!doctype html>                          <html lang=\"ko\" data-dark=\"false\"> <head> <meta charset=\"utf-8\"> <title>NAVER</title> <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"> <meta name=\"viewport\" content=\"width=1190\"> <meta name=\"apple-mobile-web-app-title\" content=\"NAVER\"/> <meta name=\"robots\" content=\"index,nofollow\"/> <meta name=\"description\" content=\"네이버 메인에서 다양한 정보와 유용한 컨텐츠를 만나 보세요\"/>  \n",
      "\n",
      "\"og:title\" content=\"네이버\">  \n",
      "\n",
      "\"og:url\" content=\"https://www.naver.com/\"> \n"
     ]
    }
   ],
   "source": [
    "content0 = html_data.split('<meta property=')[0]\n",
    "content1 = html_data.split('<meta property=')[1]\n",
    "content2 = html_data.split('<meta property=')[2]\n",
    "print(content0,'\\n')\n",
    "print(content1,'\\n')\n",
    "print(content2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://search.naver.com/search.naver'\n",
    "params = {'query' : '빅데이터'}\n",
    "response = requests.get(URL,params=params)\n",
    "response.status_code\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9603b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://comic.naver.com/webtoon/detail'\n",
    "params = {'titleId':784255,'no':29,'weekday':'wed'}\n",
    "response = requests.get(URL,params=params)\n",
    "response.status_code\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a9564658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'공지사항'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. 네이버 사이트에서 '공지사항' 출력(파이썬 인덱싱, 함수 / 정규표현식)\n",
    "URL = 'http://naver.com'\n",
    "response = requests.get(URL)\n",
    "a = re.search('공지사항',response.text)\n",
    "a.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3e372526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'공지사항'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr = response.text.find('공지사항')\n",
    "response.text[rr:rr+4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774ffed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['메일', '카페', '블로그', '지식iN', '쇼핑']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [과제] 네이버 홈페이지에 있는 ['메일','카페','블로그','지식iN','쇼핑']을 출력하세요.\n",
    "import requests\n",
    "import re\n",
    "URL = 'http://naver.com'\n",
    "response = requests.get(URL)\n",
    "# 너무 데이터가 많아서 출력을 원하는 요소들이 있는 구간만 따로 추출\n",
    "a = re.search('NM_FAVORITE.+shoplive',response.text, re.DOTALL)\n",
    "a.group()\n",
    "# 추출한 데이터 a 안에서 정규표현식으로 추출\n",
    "b = re.findall('[가-힣]+[a-zA-Z]*',a.group())\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2f1942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메일\n",
      "카페\n",
      "블로그\n",
      "지식iN\n",
      "쇼핑\n"
     ]
    }
   ],
   "source": [
    "# [과제] 네이버 홈페이지에 있는 ['메일','카페','블로그','지식iN','쇼핑']을 출력하세요.\n",
    "URL = 'http://naver.com'\n",
    "response = requests.get(URL).text\n",
    "soup = BeautifulSoup(response,'html.parser')\n",
    "texts = soup.select('#NM_FAVORITE > div.group_nav > ul.list_nav.type_fix > li > a',limit=5)\n",
    "for i in texts:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d57701",
   "metadata": {},
   "source": [
    "BeoutifulSoup 모듈\n",
    "\n",
    "- 홈페이지 내 데이터를 쉽게 추출할 수 있게 해주는 파이썬 외부 라이브러리\n",
    "- 웹 문서 내 수많은 HTML 태그들을 parser를 활용해 사용하기 편하 파이썬 객체로 만들어 제공\n",
    "- 웹 문서 구조를 알고 있다면 편하게 데이터를 뽑아 활용할 수 있음\n",
    "- BS는 HTML 문서를 태그를 기반으로 구조화하여 태그로 원하는 데이터를 찾아가는 형식 \n",
    "- find() : HTML의 해당 태그에 대한 첫번째 정보를 가져옴\n",
    "    - find(속성='값') : HTML 해당 속성과 일치하는 값에 대한 첫번째 정보를 가져옴\n",
    "- find_all(), findAll\n",
    "    - HTML의 해당 태그에 대한 모든 정보를 리스트 형식으로 가져옴. limit 옵션으로 개수지정 가능\n",
    "    - CSS 속성으로 필터링(class_로 클래스를 직접 사용 혹은 attrs에서 속성 = 값으로 필터링)\n",
    "- select_one, select()\n",
    "    - CSS 선택자를 활용하여 원하는 정보를 가져옴(태그를 검색하는 find,find_all과 비슷함)\n",
    "    - class는 . , id는 #로 표시함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a26a5e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.10.0 soupsieve-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6ed01cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   crawl\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p align=\"center\" class=\"a\">\n",
      "   text1\n",
      "  </p>\n",
      "  <p align=\"center\" class=\"b\">\n",
      "   text2\n",
      "  </p>\n",
      "  <p align=\"center\" class=\"c\">\n",
      "   text3\n",
      "  </p>\n",
      "  <div>\n",
      "   <img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html_doc = \"\"\"\n",
    "<html lang=\"en\">\n",
    "<head><title>crawl</title></head>\n",
    "<body>\n",
    "<p class=\"a\" align=\"center\"> text1</p>\n",
    "<p class=\"b\" align=\"center\"> text2</p>\n",
    "<p class=\"c\" align=\"center\"> text3</p>\n",
    "<div><img src=\"/source\" width=\"300\" height=\"200\"></div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html_doc,'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6a81923c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ver.com/banner/details/mousegesture?=main&wpid=RydDy7\"\\ndata-clk=\"dropbanner1b\"\\n></a\\n><i class=\"_1KncATpM _1yl_Ow6o\"><span class=\"blind\">NAVER whale</span></i\\n><img\\nsrc=\"https://static-whale.pstatic.ne'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'http://naver.com'\n",
    "req = requests.get(URL)\n",
    "html = req.text\n",
    "html.find('blind')\n",
    "html[9800:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ff04bebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NAVER whale'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html,'html.parser')\n",
    "result = soup.find(class_='blind')\n",
    "result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "25993180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'스크레이핑이란?'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <h1 id = \"title\">스크레이핑이란?</h1>\n",
    "  <p id = \"body\">웹 페이지를 분석하는 것</p>\n",
    "  <p>원하는 부분을 추출하는 것</p>\n",
    "  <p>원하는 부분을 하나 더 추출하는 것</p>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "body = soup.find(id='body')\n",
    "title = soup.find(id='title')\n",
    "body.text\n",
    "title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "02d60c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'스크레이핑이란?'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1 = soup.html.body.h1.string\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5dda7490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'웹 페이지를 분석하는 것'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = soup.html.body.p\n",
    "p1.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fb45666b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>원하는 부분을 추출하는 것</p>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next_sibling 다음항목(공백도 포함) ,previous_sibling 앞에것\n",
    "p2 = p1.next_sibling.next_sibling\n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "56e274de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웹 페이지를 분석하는 것\n",
      "원하는 부분을 추출하는 것\n",
      "원하는 부분을 하나 더 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "# find_all()\n",
    "texts = soup.find_all('p')\n",
    "for text in texts:\n",
    "    print(text.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b16f0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "  <ul>\n",
    "    <li><a href=\"http://www.naver.com\">naver</a></li>\n",
    "    <li><a href=\"http://www.daum.net\">daum</a></li>\n",
    "  </ul>\n",
    "</body></html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naver > http://www.naver.com\n",
    "# daum > http://www.daum.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c2e59eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "ee9c108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naver >  http://www.naver.com\n",
      "daum >  http://www.daum.net\n"
     ]
    }
   ],
   "source": [
    "links = soup.find_all('a')\n",
    "for i in links:\n",
    "    print(i.text,'> ',i.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11abe363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'기상청 육상 중기예보'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs4 와 정규표현식을 같이사용\n",
    "import urllib\n",
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "res = req.urlopen(url)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "title = soup.find('title').string\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e39cbdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'기상청 육상 중기예보'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "res = requests.get(url).text\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "title = soup.find('title').string\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "54ed56e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'○ (강수) 12일(토) 오후 제주도에 비가 시작되어 13일(일) 남부지방으로 확대되겠으며, 13일(일)~14일(월) 강원영동에는 비 또는 눈이 오겠습니다. <br />○ (기온) 이번 예보기간 아침 기온은 -9~6도, 낮 기온은 1~13도로 어제(8일, 아침최저기온 -10~0도, 낮최고기온 5~9도)보다 높겠습니다.<br />○ (해상) 13(일)~14일(월) 동해상과 남해동부해상, 제주도해상에서는 물결이 2.0~4.0m로 매우 높게 일겠습니다.<br />○ (주말전망) 12일(토)은 구름많겠으나, 제주도에는 비가 오겠으며, 13일(일)은 대체로 흐리고 전라권과 경상권, 제주도에 비가, 강원영동에는 비 또는 눈이 오겠습니다. <br />              아침 기온은 -4~6도, 낮 기온은 6~13도가 되겠습니다.<br />* 12일(토)~14일(월) 강수는 남쪽을 지나는 저기압의 위치와 이동속도에 따라 변동성이 있겠고, 13일(일)~14일(월) 강원영동에는 많은 강수량이 예상되나 기온의 변화에 <br />  따라 강수형태(비 또는 눈)가 달라질 수 있으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf = soup.find('wf').string\n",
    "wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "efbc175a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' (강수) 12일(토) 오후 제주도에 비가 시작되어 13일(일) 남부지방으로 확대되겠으며, 13일(일)~14일(월) 강원영동에는 비 또는 눈이 오겠습니다.   (기온) 이번 예보기간 아침 기온은 -9~6도, 낮 기온은 1~13도로 어제(8일, 아침최저기온 -10~0도, 낮최고기온 5~9도)보다 높겠습니다.  (해상) 13(일)~14일(월) 동해상과 남해동부해상, 제주도해상에서는 물결이 2.0~4.0m로 매우 높게 일겠습니다.  (주말전망) 12일(토)은 구름많겠으나, 제주도에는 비가 오겠으며, 13일(일)은 대체로 흐리고 전라권과 경상권, 제주도에 비가, 강원영동에는 비 또는 눈이 오겠습니다.                아침 기온은 -4~6도, 낮 기온은 6~13도가 되겠습니다.  12일(토)~14일(월) 강수는 남쪽을 지나는 저기압의 위치와 이동속도에 따라 변동성이 있겠고, 13일(일)~14일(월) 강원영동에는 많은 강수량이 예상되나 기온의 변화에    따라 강수형태(비 또는 눈)가 달라질 수 있으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = re.sub('[<br/>○*]','',wf)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "0f102e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(강수) 12일(토) 오후 제주도에 비가 시작되어 13일(일) 남부지방으로 확대되겠으며, 13일(일)~14일(월) 강원영동에는 비 또는 눈이 오겠습니다.(기온) 이번 예보기간 아침 기온은 -9~6도, 낮 기온은 1~13도로 어제(8일, 아침최저기온 -10~0도, 낮최고기온 5~9도)보다 높겠습니다.(해상) 13(일)~14일(월) 동해상과 남해동부해상, 제주도해상에서는 물결이 2.0~4.0m로 매우 높게 일겠습니다.(주말전망) 12일(토)은 구름많겠으나, 제주도에는 비가 오겠으며, 13일(일)은 대체로 흐리고 전라권과 경상권, 제주도에 비가, 강원영동에는 비 또는 눈이 오겠습니다. 아침 기온은 -4~6도, 낮 기온은 6~13도가 되겠습니다. 12일(토)~14일(월) 강수는 남쪽을 지나는 저기압의 위치와 이동속도에 따라 변동성이 있겠고, 13일(일)~14일(월) 강원영동에는 많은 강수량이 예상되나 기온의 변화에  따라 강수형태(비 또는 눈)가 달라질 수 있으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = re.findall('[^a-zA-Z0-9]?[0-9가-힣]+[^A-Z0-9]?',wf)\n",
    "''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23be677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(강수) 13일(일) 남부지방과 제주도에는 흐리고 비가 오겠으며, 13일(일)~14일(월) 강원영동에는 비 또는 눈이 오겠습니다.(기온) 이번 예보기간 아침 기온은 -11~7도로 어제(9일, 아침최저기온 -11~2도)와 비슷하거나 조금 높겠고, 낮 기온은 1~11도로 어제(9일, 낮최고기온 5~12도)보다 낮겠습니다.(해상) 13일(일)~14일(월) 동해상과 남해동부해상, 제주도해상에서는 물결이 2.0~4.0m로 매우 높게 일겠습니다.(주말전망) 12일(토)은 전국이 가끔 구름많겠으며, 13일(일)은 전국이 대체로 흐리고 남부지방과 제주도에 비가, 강원영동에는 비 또는 눈이 오겠습니다. 아침 기온은 -6~7도, 낮 기온은 6~14도가 되겠습니다. 13일(일)~14일(월) 강수는 남쪽을 지나는 저기압의 위치와 이동속도에 따라 변동성이 있겠고, 강원영동에는 많은 강수량이 예상되나 기온의 변화에 따라 강수형태(비 또는 눈)가  달라질 수 있으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비/눈\n",
      "흐리고 비/눈\n",
      "흐리고 눈\n",
      "흐리고 눈\n",
      "구름많음\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "맑음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "구름많음\n",
      "흐림\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "구름많음\n",
      "흐림\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "구름많음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "구름많음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "구름많음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "구름많음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "구름많음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "구름많음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "흐림\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "흐림\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "흐림\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "흐림\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "흐림\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "흐림\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "맑음\n",
      "맑음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "맑음\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "흐림\n",
      "흐리고 비\n",
      "흐리고 비\n",
      "흐림\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "구름많음\n",
      "흐림\n",
      "흐림\n",
      "흐림\n"
     ]
    }
   ],
   "source": [
    "# [과제] wf 태그는 모두 출력\n",
    "import urllib\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "res = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "texts = soup.find_all('wf')\n",
    "for i in texts:\n",
    "    text = re.findall('[^a-zA-Z0-9]?[0-9가-힣]+[^A-Z0-9]?',i.string)\n",
    "    print(''.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://naver.com'\n",
    "text = requests.get(url).text\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1445c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a>\n",
      "<span class=\"blind\">NAVER whale</span>\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "url = 'http://naver.com'\n",
    "response = urllib.request.urlopen(url)\n",
    "byte_data = response.read()\n",
    "html = byte_data.decode('utf-8')\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "print(soup.find('a'))\n",
    "print(soup.find(class_='blind'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "3ed56730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"#newsstand\"><span>뉴스스탠드 바로가기</span></a>"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('a',limit=2)\n",
    "soup.find_all('a',limit=2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "1fbe2145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"blind\">해피빈</span>,\n",
       " <span class=\"blind\">검색</span>,\n",
       " <span class=\"blind\">한글 입력기</span>,\n",
       " <span class=\"blind\">자동완성 레이어</span>]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('span',class_='blind')[3:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "1b8d5338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"blind\">한글 입력기</span>,\n",
       " <span class=\"blind\">자동완성 레이어</span>,\n",
       " <span class=\"ico_arr\"></span>,\n",
       " <span class=\"blind\">쇼핑</span>,\n",
       " <span class=\"blind\">쇼핑LIVE</span>]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('span',class_=['blind','ico_arr'])[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ae9fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"blind\">한글 입력기</span>,\n",
       " <span class=\"blind\">자동완성 레이어</span>,\n",
       " <span class=\"ico_arr\"></span>,\n",
       " <span class=\"blind\">쇼핑</span>,\n",
       " <span class=\"blind\">쇼핑LIVE</span>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('span',attrs={'class':('blind','ico_arr')})[5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "5ce15382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['네이버']"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(string = '네이버')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "affb6624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['네이버', '네이버를 시작페이지로', '쥬니어네이버', '언론사가 직접 편집한 뉴스들을 네이버 홈에서 바로 보실 수 있습니다.', '네이버스포츠', '[기획전] 2022년 신상부터 스테디셀러 상품 네이버 단독 특가!', '네이버스포츠', '네이버스포츠', '네이버스포츠', '네이버스포츠', '네이버스포츠', '네이버스포츠', '네이버스포츠', '네이버스포츠', '네이버스포츠', '네이버스포츠', '네이버스포츠', '크보연구소_네이버스포츠', '네이버 개발자 센터', '네이버 D2', '네이버 D2SF', '네이버 랩스', '네이버 정책 및 약관', '네이버 정책']\n"
     ]
    }
   ],
   "source": [
    "print(soup.find_all(string = re.compile('네이버')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "f0bcdc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"blind\">영화검색 영역</span>\n",
      "영화검색 영역\n",
      "['blind']\n"
     ]
    }
   ],
   "source": [
    "req = requests.get('http://movie.naver.com')\n",
    "html = req.text\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "text = soup.find('span',attrs={'class':'blind'})\n",
    "print(text)\n",
    "print(text.get_text())\n",
    "print(text.get('class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "82c1c652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'위키북스 도서'"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"\"\"\n",
    "<html><body>\n",
    "<div id=\"meigen\">\n",
    "  <h1>위키북스 도서</h1>\n",
    "  <ul class=\"items\">\n",
    "    <li>유니티 게임 이펙트 입문</li>\n",
    "    <li>스위프트로 시작하는 아이폰 앱 개발 교과서</li>\n",
    "    <li>모던 웹사이트 디자인의 정석</li>\n",
    "  </ul>\n",
    "</div>\n",
    "</body></html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "h1 = soup.select_one('div#meigen > h1').string\n",
    "h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "baf392f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유니티 게임 이펙트 입문\n",
      "스위프트로 시작하는 아이폰 앱 개발 교과서\n",
      "모던 웹사이트 디자인의 정석\n"
     ]
    }
   ],
   "source": [
    "items = soup.select('div#meigen > ul.items > li')\n",
    "for i in items:\n",
    "    print(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "571d5164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 환율(원화/USD) : 1,195.40\n"
     ]
    }
   ],
   "source": [
    "# Q. 네이버 환율 가져오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://finance.naver.com/marketindex/'\n",
    "req = requests.get(url).text\n",
    "soup = BeautifulSoup(req,'html.parser')\n",
    "exchange = soup.select_one('#exchangeList > li.on > a.head.usd > div > span.value').string\n",
    "print('현재 환율(원화/USD) :',exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b831bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 환율(원화/EUR) : 1,364.67\n"
     ]
    }
   ],
   "source": [
    "url = 'https://finance.naver.com/marketindex/'\n",
    "req = requests.get(url).text\n",
    "soup = BeautifulSoup(req,'html.parser')\n",
    "exchange = soup.select_one('#exchangeList > li:nth-child(3) > a.head.eur > div > span.value').string\n",
    "print('현재 환율(원화/EUR) :',exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76bc99d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 네이버 영화 조회수 랭킹 1위는 해적: 도깨비 깃발 입니다.\n"
     ]
    }
   ],
   "source": [
    "# [과제] 네이버 영화 랭킹 가져와서 첫번째 영화제목을 출력하세요\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.naver'\n",
    "req = requests.get(url).text\n",
    "soup = BeautifulSoup(req,'html.parser')\n",
    "\n",
    "first_movie = soup.select_one('#old_content > table > tbody > tr:nth-child(2) > td.title > div > a').string\n",
    "print('현재 네이버 영화 조회수 랭킹 1위는',first_movie,'입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d139de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'해적: 도깨비 깃발'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.naver?sel=cnt&date=20220208'\n",
    "res = requests.get(url).text\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "movie_top1 = soup.select_one('div.tit3 > a')\n",
    "movie_top1.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0bf1e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네이버 영화 조회수 랭킹 순위\n",
      "1위 해적: 도깨비 깃발\n",
      "2위 킹메이커\n",
      "3위 특송\n",
      "4위 나일 강의 죽음\n",
      "5위 스파이더맨: 노 웨이 홈\n",
      "6위 355\n",
      "7위 하우스 오브 구찌\n",
      "8위 씽2게더\n",
      "9위 경관의 피\n",
      "10위 킹스맨: 퍼스트 에이전트\n",
      "11위 나의 촛불\n",
      "12위 언차티드\n",
      "13위 어나더 라운드\n",
      "14위 극장판 안녕 자두야: 제주도의 비밀\n",
      "15위 듄\n",
      "16위 미싱타는 여자들\n",
      "17위 셰터드\n",
      "18위 드라이브 마이 카\n",
      "19위 만년이 지나도 변하지 않는 게 있어\n",
      "20위 인민을 위해 복무하라\n",
      "21위 더 배트맨\n",
      "22위 트로트는 인생이다\n",
      "23위 굿 보스\n",
      "24위 짬뽕비권\n",
      "25위 창극 변강쇠 점 찍고 옹녀\n",
      "26위 수퍼모델\n",
      "27위 나이트메어 앨리\n",
      "28위 장민호 드라마 최종회\n",
      "29위 인어가 잠든 집\n",
      "30위 극장판 주술회전 0\n",
      "31위 효자\n",
      "32위 가슴이 떨리는 건 너 때문\n",
      "33위 코로나\n",
      "34위 프랑스\n",
      "35위 안테벨룸\n",
      "36위 문폴\n",
      "37위 더 마더\n",
      "38위 리코리쉬 피자\n",
      "39위 이상한 나라의 수학자\n",
      "40위 웨스트 사이드 스토리\n",
      "41위 스크림\n",
      "42위 비틀즈 겟 백: 루프탑 콘서트\n",
      "43위 말할 수 없는 비밀\n",
      "44위 오리엔트 특급 살인\n",
      "45위 신들의 분노\n",
      "46위 파워 오브 도그\n",
      "47위 피그\n",
      "48위 10 아이덴티티\n",
      "49위 피드백\n",
      "50위 덩케르크\n"
     ]
    }
   ],
   "source": [
    "# [과제] 네이버 영화 랭킹 가져와서 전체 영화제목을 출력하세요.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://movie.naver.com/movie/sdb/rank/rmovie.naver'\n",
    "req = requests.get(url).text\n",
    "soup = BeautifulSoup(req,'html.parser')\n",
    "\n",
    "# 1위의 주소 : old_content > table > tbody > tr:nth-child(2) > td.title > div > a\n",
    "# 2위의 주소 : old_content > table > tbody > tr:nth-child(3) > td.title > div > a\n",
    "# 3위의 주소 : old_content > table > tbody > tr:nth-child(4) > td.title > div > a\n",
    "# 1, 2, 3위의 주소가 tr:nth-child(n) 부분의 차이만 있기에 이부분을 통일시키고 한번에 select\n",
    "\n",
    "movie_list = soup.select('#old_content > table > tbody > tr > td.title > div > a')\n",
    "print('네이버 영화 조회수 랭킹 순위')\n",
    "\n",
    "# enumerate로 인덱스와 함께 추출하여 순위표시\n",
    "for i,v in enumerate(movie_list):\n",
    "    print(f'{i+1}위 {v.string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514f4c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(강수) 13일(일)~14일(월) 강원영동에 비 또는 눈이 내리겠습니다.(기온) 이번 예보기간의 아침 기온은 -14~3도로 어제(9일, 아침최저기온 -17~-2도)와 비슷하거나 조금 높겠고, 낮 기온은 -3~7도로 어제(9일, 낮최고기온 4~10도)보다 낮겠습니다.(해상) 동해중부해상의 물결은 13일(일) 오후~14일(월) 오전에는 2.0~4.0m로 매우 높게 일겠습니다.(주말전망) 12일(토)~13일(일)은 대체로 흐리겠고, 13일(일)은 강원영동에 비 또는 눈이 내리겠습니다. 아침 기온은 -6~3도, 낮 기온은 2~10도가 되겠습니다. 13일(일)~14일(월) 강수는 남쪽을 지나는 저기압의 위치와 이동속도에 따라 변동성이 있겠고, 강원영동에는 많은 강수량이 예상되나 기온의 변화에 따라 강수형태(비 또는 눈)가  달라질 수 있으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [과제] 기상청 육상 정보에서 강원도의 지역번호는 105이다. 강원도의 날씨예보를 출력하세요.\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=105\"\n",
    "req = requests.get(url).text\n",
    "soup = BeautifulSoup(req,'html.parser')\n",
    "wf = soup.select_one('wf').string\n",
    "text = re.findall('[^a-zA-Z0-9]?[0-9가-힣]+[^A-Z0-9]?',wf)\n",
    "''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be3c9d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp?stnId=105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'(강수) 13일(일)~14일(월) 강원영동에 비 또는 눈이 내리겠습니다.(기온) 이번 예보기간의 아침 기온은 -14~3도로 어제(9일, 아침최저기온 -17~-2도)와 비슷하거나 조금 높겠고, 낮 기온은 -3~7도로 어제(9일, 낮최고기온 4~10도)보다 낮겠습니다.(해상) 동해중부해상의 물결은 13일(일) 오후~14일(월) 오전에는 2.0~4.0m로 매우 높게 일겠습니다.(주말전망) 12일(토)~13일(일)은 대체로 흐리겠고, 13일(일)은 강원영동에 비 또는 눈이 내리겠습니다. 아침 기온은 -6~3도, 낮 기온은 2~10도가 되겠습니다. 13일(일)~14일(월) 강수는 남쪽을 지나는 저기압의 위치와 이동속도에 따라 변동성이 있겠고, 강원영동에는 많은 강수량이 예상되나 기온의 변화에 따라 강수형태(비 또는 눈)가  달라질 수 있으니, 앞으로 발표되는 기상정보를 참고하기 바랍니다.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "\n",
    "api = \"http://www.kma.go.kr/weather/forecast/mid-term-rss3.jsp\"\n",
    "\n",
    "values = {\n",
    "    'stnId':'105'\n",
    "}\n",
    "params = urllib.parse.urlencode(values)\n",
    "url = api + '?' + params\n",
    "\n",
    "print('url' , url)\n",
    "\n",
    "res = urllib.request.urlopen(url)\n",
    "soup = BeautifulSoup(res,'html.parser')\n",
    "wf = soup.find('wf').string\n",
    "text = ''.join(re.findall('[^a-zA-Z0-9]?[0-9가-힣]+[^A-Z0-9]?',wf))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5949c3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국 종합 15위\n",
      "금메달1\n",
      "은메달0\n",
      "동메달1\n"
     ]
    }
   ],
   "source": [
    "# [과제] 관심 내용에 대하여 웹에서 가져와서 정규표현식, BS를 이용하여 데이터를 출력하세요.\n",
    "\n",
    "# 올림픽 시즌이니 우리나라 올림픽 순위와 메달 갯수를 가져오기로 결정\n",
    "\n",
    "url = 'https://search.naver.com/search.naver?where=nexearch&sm=tab_etc&mra=blM4&pkid=6011&qvt=0&query=%EB%B2%A0%EC%9D%B4%EC%A7%95%20%EB%8F%99%EA%B3%84%20%EC%98%AC%EB%A6%BC%ED%94%BD%20%EB%A9%94%EB%8B%AC'\n",
    "req = requests.get(url).text\n",
    "soup = BeautifulSoup(req,'html.parser')\n",
    "\n",
    "# 랭킹 주소 : #main_pack > div.sc_new.cs_common_module.case_normal.color_7._olympic > div.cm_top_wrap._sticky._custom_select._header > div.title_area.type_keep._title_area > div > span\n",
    "# 금매달 갯수 주소 : #main_pack > div.sc_new.cs_common_module.case_normal.color_7._olympic > div.cm_top_wrap._sticky._custom_select._header > div.title_area.type_keep._title_area > div > div > span.ico_medal.gold\n",
    "# 은매달 갯수 주소 : #main_pack > div.sc_new.cs_common_module.case_normal.color_7._olympic > div.cm_top_wrap._sticky._custom_select._header > div.title_area.type_keep._title_area > div > div > span.ico_medal.silver\n",
    "# 동매달 갯수 주소 : #main_pack > div.sc_new.cs_common_module.case_normal.color_7._olympic > div.cm_top_wrap._sticky._custom_select._header > div.title_area.type_keep._title_area > div > div > span.ico_medal.bronze\n",
    "ranking = soup.select_one('#main_pack > div.sc_new.cs_common_module.case_normal.color_7._olympic > div.cm_top_wrap._sticky._custom_select._header > div.title_area.type_keep._title_area > div > span').string\n",
    "medal = soup.select('#main_pack > div.sc_new.cs_common_module.case_normal.color_7._olympic > div.cm_top_wrap._sticky._custom_select._header > div.title_area.type_keep._title_area > div > div > span')\n",
    "print(ranking)\n",
    "for i in medal:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "892a55cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:30 *예정* 피겨 스케이팅 피겨 스케이팅 남자 싱글 프리 프로그램\n",
      "10:30 *예정* 스켈레톤 남자 런1\n",
      "12:00 *예정* 스켈레톤 남자 런2\n",
      "16:00 *예정* 크로스컨트리 스키 여자 10km 클래식 \n",
      "21:05 *예정* 컬링 여자 라운드 로빈\n",
      "22:30 *예정* 루지 팀 계주 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url = 'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=%EC%98%AC%EB%A6%BC%ED%94%BD+%EC%9D%BC%EC%A0%95'\n",
    "req = requests.get(url).text\n",
    "soup = BeautifulSoup(req,'html.parser')\n",
    "\n",
    "title = soup.select('#main_pack > section.sc_new.cs_common_module.case_normal.color_7._olympic > div.cm_content_wrap._selectable > div > div > div.league_schedule._panel > div > div > div > div.match_wrap.type_olympics > div > div > div > div.match_title > dl > dd:nth-child(4) > div > span.text')\n",
    "time = soup.select('#main_pack > section.sc_new.cs_common_module.case_normal.color_7._olympic > div.cm_content_wrap._selectable > div > div > div.league_schedule._panel > div > div > div > div.match_wrap.type_olympics > div > div > div > div.match_title > dl > dd:nth-child(2) > strong')\n",
    "state = soup.select('#main_pack > section.sc_new.cs_common_module.case_normal.color_7._olympic > div.cm_content_wrap._selectable > div > div > div.league_schedule._panel > div > div > div > div.match_wrap.type_olympics > div > div > div > div.match_title > dl > dd:nth-child(4) > div > span.state_mark')\n",
    "\n",
    "state_list = np.full(len(title),'*예정*')\n",
    "\n",
    "for i,v in enumerate(state):\n",
    "    state_list[i]=v.text\n",
    "\n",
    "for i,v,x in zip(title,time,state_list):\n",
    "    print(v.text,x,i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6d437e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body>\n",
       "<p align=\"center\" class=\"a\"> text1</p>\n",
       "<p align=\"center\" class=\"b\"> text2</p>\n",
       "<p align=\"center\" class=\"c\"> text3</p>\n",
       "<div>\n",
       "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
       "</div>\n",
       "</body>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html=\"\"\"\n",
    "<head>\n",
    "    <title>crawler</title>\n",
    "</head>\n",
    "<body>\n",
    "    <p class=\"a\" align=\"center\"> text1</p>\n",
    "    <p class=\"b\" align=\"center\"> text2</p>\n",
    "    <p class=\"c\" align=\"center\"> text3</p>\n",
    "    <div>\n",
    "        <img src=\"/source\" width=\"300\" height=\"200\">\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "contents = soup.find('body')\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87f7b0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 자손\n",
      "\n",
      "\n",
      "<p align=\"center\" class=\"a\"> text1</p>\n",
      " text1\n",
      "\n",
      "\n",
      "<p align=\"center\" class=\"b\"> text2</p>\n",
      " text2\n",
      "\n",
      "\n",
      "<p align=\"center\" class=\"c\"> text3</p>\n",
      " text3\n",
      "\n",
      "\n",
      "<div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "</div>\n",
      "\n",
      "\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 자식 vs 자손\n",
    "\n",
    "# print('자식')\n",
    "# for child in contents.children:\n",
    "#     print(child)\n",
    "print('\\n 자손')\n",
    "for d in contents.descendants:\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25ea1c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img height=\"200\" src=\"/source\" width=\"300\"/> \n",
      "\n",
      "<div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "img_tag = contents.find('img')\n",
    "print(img_tag,'\\n')\n",
    "print(img_tag.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0885f23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div>\n",
       " <img height=\"200\" src=\"/source\" width=\"300\"/>\n",
       " </div>,\n",
       " <body>\n",
       " <p align=\"center\" class=\"a\"> text1</p>\n",
       " <p align=\"center\" class=\"b\"> text2</p>\n",
       " <p align=\"center\" class=\"c\"> text3</p>\n",
       " <div>\n",
       " <img height=\"200\" src=\"/source\" width=\"300\"/>\n",
       " </div>\n",
       " </body>,\n",
       " \n",
       " <head>\n",
       " <title>crawler</title>\n",
       " </head>\n",
       " <body>\n",
       " <p align=\"center\" class=\"a\"> text1</p>\n",
       " <p align=\"center\" class=\"b\"> text2</p>\n",
       " <p align=\"center\" class=\"c\"> text3</p>\n",
       " <div>\n",
       " <img height=\"200\" src=\"/source\" width=\"300\"/>\n",
       " </div>\n",
       " </body>\n",
       " ]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents = img_tag.parents\n",
    "list(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1910672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body>\n",
      "<p align=\"center\" class=\"a\"> text1</p>\n",
      "<p align=\"center\" class=\"b\"> text2</p>\n",
      "<p align=\"center\" class=\"c\"> text3</p>\n",
      "<div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "</div>\n",
      "</body> \n",
      "\n",
      "<div>\n",
      "<img height=\"200\" src=\"/source\" width=\"300\"/>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print(img_tag.find_parent('body'),'\\n')\n",
    "print(img_tag.find_parent('div'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46930b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"center\" class=\"a\"> text1</p>,\n",
       " <p align=\"center\" class=\"b\"> text2</p>,\n",
       " <p align=\"center\" class=\"c\"> text3</p>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tag = soup.find_all('p')\n",
    "p_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df5d5af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"center\" class=\"b\"> text2</p>,\n",
       " <p align=\"center\" class=\"c\"> text3</p>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tag = soup.find_all('p',class_=['c','b'])\n",
    "p_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a464dff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"center\" class=\"b\"> text2</p>,\n",
       " <p align=\"center\" class=\"c\"> text3</p>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tag = soup.find_all('p',attrs = {'class':{'c','b'}})\n",
    "p_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ad3d5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n$15.00\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 부모 다루기\n",
    "url = 'https://www.pythonscraping.com/pages/page3.html'\n",
    "url_req = requests.get(url).text\n",
    "soup = BeautifulSoup(url_req,'html.parser')\n",
    "soup.select_one('#gift1 > td:nth-child(3)').string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d96db072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$15.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.pythonscraping.com/pages/page3.html'\n",
    "url_req = requests.get(url)\n",
    "html = url_req.text\n",
    "bs = BeautifulSoup(html,'html.parser')\n",
    "print(bs.find('img',attrs={'src':'../img/gifts/img1.jpg'}).parent.previous_sibling.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91064fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$1.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.pythonscraping.com/pages/page3.html'\n",
    "url_req = requests.get(url)\n",
    "html = url_req.text\n",
    "bs = BeautifulSoup(html,'html.parser')\n",
    "print(bs.find('img',attrs={'src':'../img/gifts/img6.jpg'}).parent.previous_sibling.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d855a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"logo_default\">\n",
      "<a class=\"logo_naver\" data-clk=\"top.logo\" href=\"/\"><span class=\"blind\">네이버</span></a>\n",
      "</h1> \n",
      "\n",
      "<h2 class=\"blind\">뉴스스탠드</h2> \n",
      "\n",
      "<h2 class=\"blind\">주제별 캐스트</h2> \n",
      "\n",
      "<h2 class=\"title\"><span class=\"blind\">BEIJING 2022</span></h2> \n",
      "\n",
      "<h2 class=\"blind\">Sign in</h2> \n",
      "\n",
      "<h2 class=\"blind\">타임스퀘어</h2> \n",
      "\n",
      "<h3 class=\"title\"><a href=\"https://www.naver.com/NOTICE\">공지사항</a> </h3> \n",
      "\n",
      "<h3 class=\"title\">Creators</h3> \n",
      "\n",
      "<h3 class=\"title\">Partners</h3> \n",
      "\n",
      "<h3 class=\"title\">Developers</h3> \n",
      "\n",
      "<h3 class=\"blind\">네이버 정책 및 약관</h3> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = requests.get('http://naver.com').text\n",
    "bs = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "hlists = bs.findAll({'h1','h2','h3','h4','h5','h6'})\n",
    "for h in hlists:\n",
    "    print(h,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "891315db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'뉴스스탠드'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hlists = bs.find({'h1','h2','h3','h4','h5','h6'},text='뉴스스탠드')\n",
    "hlists.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4fac1e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 뉴스스탠드  구독한 언론사 전체언론사    리스트형  썸네일형  설정  \n"
     ]
    }
   ],
   "source": [
    "ttls = bs.findAll(id = 'NM_NEWSSTAND_TITLE')\n",
    "for t in ttls:\n",
    "    print(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "52db6cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "국가기술자격\n",
      "\n",
      "\n",
      "관련 근거\n",
      "\n",
      "국가기술자격법 및 동법 시행령\n",
      "\n",
      "\n",
      "\n",
      "빅데이터분석기사 정의\n",
      "\n",
      "빅데이터 이해를 기반으로 빅데이터 분석 기획, 빅데이터 수집·저장·처리, 빅데이터 분석 및 시각화를 수행하는 실무자를 말한다.\n",
      "\n",
      "\n",
      "\n",
      "빅데이터분석기사의 필요성\n",
      "\n",
      "전 세계적으로 빅데이터가 미래성장동력으로 인식돼, 각국 정부에서는 관련 기업투자를 끌어내는 등 국가·기업의 주요 전략분야로 부상하고 있다.\n",
      " 국가와 기업의 경쟁력 확보를 위해 빅데이터 분석 전문가의 수요는 증가하고 있으나, 수요 대비 공급 부족으로 인력 확보에 어려움이 높은 실정이다. \n",
      "이에 정부차원에서 빅데이터 분석 전문가 양성과 함께 체계적으로 역량을 검증할 수 있는 국가기술자격 수요가 높은 편이다.\n",
      "\n",
      "\n",
      "\n",
      "빅데이터분석기사의 직무\n",
      "\n",
      "대용량의 데이터 집합으로부터 유용한 정보를 찾고 결과를 예측하기 위해 목적에 따라 분석기술과 방법론을 기반으로 정형/비정형 대용량 데이터를 구축, 탐색, 분석하고 시각화를 수행하는 업무를 수행한다.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.dataq.or.kr/www/sub/a_07.do'\n",
    "html = requests.get(url).text\n",
    "bs1 = BeautifulSoup(html,'html.parser')\n",
    "li = bs1.select('#tab1')\n",
    "for i in li:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e4bab8",
   "metadata": {},
   "source": [
    "[과제] 아래와 같이 원본 데이터를 유지하면서 빈줄 없이 출력하세요.  \n",
    "국가기술자격  \n",
    "관련 근거  \n",
    "국가기술자격법 및 동법 시행령  \n",
    "빅데이터분석기사 정의  \n",
    "빅데이터 이해를 기반으로 빅데이터 분석 기획, 빅데이터 수집·저장·처리, 빅데이터 분석 및 시각화를 수행하는 실무자를 말한다.  \n",
    "빅데이터분석기사의 필요성  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afba92f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "국가기술자격\n",
      "관련 근거\n",
      "국가기술자격법 및 동법 시행령\n",
      "빅데이터분석기사 정의\n",
      "빅데이터 이해를 기반으로 빅데이터 분석 기획, 빅데이터 수집·저장·처리, 빅데이터 분석 및 시각화를 수행하는 실무자를 말한다.\n",
      "빅데이터분석기사의 필요성\n",
      "전 세계적으로 빅데이터가 미래성장동력으로 인식돼, 각국 정부에서는 관련 기업투자를 끌어내는 등 국가·기업의 주요 전략분야로 부상하고 있다.\n",
      " 국가와 기업의 경쟁력 확보를 위해 빅데이터 분석 전문가의 수요는 증가하고 있으나, 수요 대비 공급 부족으로 인력 확보에 어려움이 높은 실정이다. \n",
      "이에 정부차원에서 빅데이터 분석 전문가 양성과 함께 체계적으로 역량을 검증할 수 있는 국가기술자격 수요가 높은 편이다.\n",
      "빅데이터분석기사의 직무\n",
      "대용량의 데이터 집합으로부터 유용한 정보를 찾고 결과를 예측하기 위해 목적에 따라 분석기술과 방법론을 기반으로 정형/비정형 대용량 데이터를 구축, 탐색, 분석하고 시각화를 수행하는 업무를 수행한다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [과제] 아래와 같이 원본 데이터를 유지하면서 빈줄 없이 출력하세요.\n",
    "\n",
    "import re \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.dataq.or.kr/www/sub/a_07.do'\n",
    "html = requests.get(url).text\n",
    "bs1 = BeautifulSoup(html,'html.parser')\n",
    "li = bs1.select_one('#tab1').text\n",
    "# print(li)\n",
    "li1 = re.sub('\\n\\n','\\n',li)\n",
    "# print(li1)\n",
    "li2 = re.sub('\\n\\n','\\n',li1)\n",
    "print(li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e59468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "국가기술자격\n",
      "관련 근거\n",
      "국가기술자격법 및 동법 시행령\n",
      "빅데이터분석기사 정의\n",
      "빅데이터 이해를 기반으로 빅데이터 분석 기획, 빅데이터 수집·저장·처리, 빅데이터 분석 및 시각화를 수행하는 실무자를 말한다.\n",
      "빅데이터분석기사의 필요성\n",
      "전 세계적으로 빅데이터가 미래성장동력으로 인식돼, 각국 정부에서는 관련 기업투자를 끌어내는 등 국가·기업의 주요 전략분야로 부상하고 있다.\n",
      " 국가와 기업의 경쟁력 확보를 위해 빅데이터 분석 전문가의 수요는 증가하고 있으나, 수요 대비 공급 부족으로 인력 확보에 어려움이 높은 실정이다. \n",
      "이에 정부차원에서 빅데이터 분석 전문가 양성과 함께 체계적으로 역량을 검증할 수 있는 국가기술자격 수요가 높은 편이다.\n",
      "빅데이터분석기사의 직무\n",
      "대용량의 데이터 집합으로부터 유용한 정보를 찾고 결과를 예측하기 위해 목적에 따라 분석기술과 방법론을 기반으로 정형/비정형 대용량 데이터를 구축, 탐색, 분석하고 시각화를 수행하는 업무를 수행한다.\n"
     ]
    }
   ],
   "source": [
    "lis = bs1.findAll({'h3','h4','p'},limit=11)\n",
    "for i in lis:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3a017866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='\\n'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.dataq.or.kr/www/sub/a_07.do'\n",
    "html = requests.get(url).text\n",
    "bs1 = BeautifulSoup(html,'html.parser')\n",
    "li = bs1.select_one('#tab1').text\n",
    "# while 1:\n",
    "re.search('[\\n\\n]',li)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1a83128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tag.prettify of <html>\n",
      "<head>\n",
      "<style>\n",
      ".green{\n",
      "\tcolor:#55ff55;\n",
      "}\n",
      ".red{\n",
      "\tcolor:#ff5555;\n",
      "}\n",
      "#text{\n",
      "\twidth:50%;\n",
      "}\n",
      "</style>\n",
      "</head>\n",
      "<body>\n",
      "<h1>War and Peace</h1>\n",
      "<h2>Chapter 1</h2>\n",
      "<div id=\"text\">\n",
      "\"<span class=\"red\">Well, Prince, so Genoa and Lucca are now just family estates of the\n",
      "Buonapartes. But I warn you, if you don't tell me that this means war,\n",
      "if you still try to defend the infamies and horrors perpetrated by\n",
      "that Antichrist- I really believe he is Antichrist- I will have\n",
      "nothing more to do with you and you are no longer my friend, no longer\n",
      "my 'faithful slave,' as you call yourself! But how do you do? I see\n",
      "I have frightened you- sit down and tell me all the news.</span>\"\n",
      "<p></p>\n",
      "It was in July, 1805, and the speaker was the well-known <span class=\"green\">Anna\n",
      "Pavlovna Scherer</span>, maid of honor and favorite of the <span class=\"green\">Empress Marya\n",
      "Fedorovna</span>. With these words she greeted <span class=\"green\">Prince Vasili Kuragin</span>, a man\n",
      "of high rank and importance, who was the first to arrive at her\n",
      "reception. <span class=\"green\">Anna Pavlovna</span> had had a cough for some days. She was, as\n",
      "she said, suffering from la grippe; grippe being then a new word in\n",
      "<span class=\"green\">St. Petersburg</span>, used only by the elite.\n",
      "<p></p>\n",
      "All her invitations without exception, written in French, and\n",
      "delivered by a scarlet-liveried footman that morning, ran as follows:\n",
      "<p></p>\n",
      "\"<span class=\"red\">If you have nothing better to do, Count [or Prince], and if the\n",
      "prospect of spending an evening with a poor invalid is not too\n",
      "terrible, I shall be very charmed to see you tonight between 7 and 10-\n",
      "Annette Scherer.</span>\"\n",
      "<p></p>\n",
      "\"<span class=\"red\">Heavens! what a virulent attack!</span>\" replied <span class=\"green\">the prince</span>, not in the\n",
      "least disconcerted by this reception. He had just entered, wearing\n",
      "an embroidered court uniform, knee breeches, and shoes, and had\n",
      "stars on his breast and a serene expression on his flat face. He spoke\n",
      "in that refined French in which our grandfathers not only spoke but\n",
      "thought, and with the gentle, patronizing intonation natural to a\n",
      "man of importance who had grown old in society and at court. He went\n",
      "up to <span class=\"green\">Anna Pavlovna</span>, kissed her hand, presenting to her his bald,\n",
      "scented, and shining head, and complacently seated himself on the\n",
      "sofa.\n",
      "<p></p>\n",
      "\"<span class=\"red\">First of all, dear friend, tell me how you are. Set your friend's\n",
      "mind at rest,</span>\" said he without altering his tone, beneath the\n",
      "politeness and affected sympathy of which indifference and even\n",
      "irony could be discerned.\n",
      "<p></p>\n",
      "\"<span class=\"red\">Can one be well while suffering morally? Can one be calm in times\n",
      "like these if one has any feeling?</span>\" said <span class=\"green\">Anna Pavlovna</span>. \"<span class=\"red\">You are\n",
      "staying the whole evening, I hope?</span>\"\n",
      "<p></p>\n",
      "\"<span class=\"red\">And the fete at the English ambassador's? Today is Wednesday. I\n",
      "must put in an appearance there,</span>\" said <span class=\"green\">the prince</span>. \"<span class=\"red\">My daughter is\n",
      "coming for me to take me there.</span>\"\n",
      "<p></p>\n",
      "\"<span class=\"red\">I thought today's fete had been canceled. I confess all these\n",
      "festivities and fireworks are becoming wearisome.</span>\"\n",
      "<p></p>\n",
      "\"<span class=\"red\">If they had known that you wished it, the entertainment would\n",
      "have been put off,</span>\" said <span class=\"green\">the prince</span>, who, like a wound-up clock, by\n",
      "force of habit said things he did not even wish to be believed.\n",
      "<p></p>\n",
      "\"<span class=\"red\">Don't tease! Well, and what has been decided about Novosiltsev's\n",
      "dispatch? You know everything.</span>\"\n",
      "<p></p>\n",
      "\"<span class=\"red\">What can one say about it?</span>\" replied <span class=\"green\">the prince</span> in a cold,\n",
      "listless tone. \"<span class=\"red\">What has been decided? They have decided that\n",
      "Buonaparte has burnt his boats, and I believe that we are ready to\n",
      "burn ours.</span>\"\n",
      "<p></p>\n",
      "<span class=\"green\">Prince Vasili</span> always spoke languidly, like an actor repeating a\n",
      "stale part. <span class=\"green\">Anna Pavlovna</span> Scherer on the contrary, despite her forty\n",
      "years, overflowed with animation and impulsiveness. To be an\n",
      "enthusiast had become her social vocation and, sometimes even when she\n",
      "did not feel like it, she became enthusiastic in order not to\n",
      "disappoint the expectations of those who knew her. The subdued smile\n",
      "which, though it did not suit her faded features, always played\n",
      "round her lips expressed, as in a spoiled child, a continual\n",
      "consciousness of her charming defect, which she neither wished, nor\n",
      "could, nor considered it necessary, to correct.\n",
      "<p></p>\n",
      "In the midst of a conversation on political matters <span class=\"green\">Anna Pavlovna</span>\n",
      "burst out:\n",
      "<p></p>\n",
      "\"<span class=\"red\">Oh, don't speak to me of Austria. Perhaps I don't understand\n",
      "things, but Austria never has wished, and does not wish, for war.\n",
      "She is betraying us! Russia alone must save Europe. Our gracious\n",
      "sovereign recognizes his high vocation and will be true to it. That is\n",
      "the one thing I have faith in! Our good and wonderful sovereign has to\n",
      "perform the noblest role on earth, and he is so virtuous and noble\n",
      "that God will not forsake him. He will fulfill his vocation and\n",
      "crush the hydra of revolution, which has become more terrible than\n",
      "ever in the person of this murderer and villain! We alone must\n",
      "avenge the blood of the just one.... Whom, I ask you, can we rely\n",
      "on?... England with her commercial spirit will not and cannot\n",
      "understand the Emperor Alexander's loftiness of soul. She has\n",
      "refused to evacuate Malta. She wanted to find, and still seeks, some\n",
      "secret motive in our actions. What answer did Novosiltsev get? None.\n",
      "The English have not understood and cannot understand the\n",
      "self-abnegation of our Emperor who wants nothing for himself, but only\n",
      "desires the good of mankind. And what have they promised? Nothing! And\n",
      "what little they have promised they will not perform! Prussia has\n",
      "always declared that Buonaparte is invincible, and that all Europe\n",
      "is powerless before him.... And I don't believe a word that Hardenburg\n",
      "says, or Haugwitz either. This famous Prussian neutrality is just a\n",
      "trap. I have faith only in God and the lofty destiny of our adored\n",
      "monarch. He will save Europe!</span>\"\n",
      "<p></p>\n",
      "She suddenly paused, smiling at her own impetuosity.\n",
      "<p></p>\n",
      "\"<span class=\"red\">I think,</span>\" said <span class=\"green\">the prince</span> with a smile, \"<span class=\"red\">that if you had been\n",
      "sent instead of our dear <span class=\"green\">Wintzingerode</span> you would have captured the\n",
      "<span class=\"green\">King of Prussia</span>'s consent by assault. You are so eloquent. Will you\n",
      "give me a cup of tea?</span>\"\n",
      "<p></p>\n",
      "\"<span class=\"red\">In a moment. A propos,</span>\" she added, becoming calm again, \"<span class=\"red\">I am\n",
      "expecting two very interesting men tonight, <span class=\"green\">le Vicomte de Mortemart</span>,\n",
      "who is connected with the <span class=\"green\">Montmorencys</span> through the <span class=\"green\">Rohans</span>, one of\n",
      "the best French families. He is one of the genuine emigres, the good\n",
      "ones. And also the <span class=\"green\">Abbe Morio</span>. Do you know that profound thinker? He\n",
      "has been received by <span class=\"green\">the Emperor</span>. Had you heard?</span>\"\n",
      "<p></p>\n",
      "\"<span class=\"red\">I shall be delighted to meet them,</span>\" said <span class=\"green\">the prince</span>. \"<span class=\"red\">But tell me,</span>\"\n",
      "he added with studied carelessness as if it had only just occurred\n",
      "to him, though the question he was about to ask was the chief motive\n",
      "of his visit, \"<span class=\"red\">is it true that the Dowager Empress wants Baron Funke\n",
      "to be appointed first secretary at Vienna? The baron by all accounts\n",
      "is a poor creature.</span>\"\n",
      "<p></p>\n",
      "<span class=\"green\">Prince Vasili</span> wished to obtain this post for his son, but others\n",
      "were trying through the <span class=\"green\">Dowager Empress Marya Fedorovna</span> to secure it\n",
      "for <span class=\"green\">the baron</span>.\n",
      "<p></p>\n",
      "<span class=\"green\">Anna Pavlovna</span> almost closed her eyes to indicate that neither she\n",
      "nor anyone else had a right to criticize what <span class=\"green\">the Empress</span> desired or\n",
      "was pleased with.\n",
      "<p></p>\n",
      "\"<span class=\"red\">Baron Funke has been recommended to the Dowager Empress by her\n",
      "sister,</span>\" was all she said, in a dry and mournful tone.\n",
      "<p></p>\n",
      "As she named <span class=\"green\">the Empress</span>, <span class=\"green\">Anna Pavlovna's</span> face suddenly assumed an\n",
      "expression of profound and sincere devotion and respect mingled with\n",
      "sadness, and this occurred every time she mentioned her illustrious\n",
      "patroness. She added that <span class=\"green\">Her Majesty</span> had deigned to show <span class=\"green\">Baron\n",
      "Funke</span>, and again her face clouded over with sadness.\n",
      "<p></p>\n",
      "<span class=\"green\">The prince</span> was silent and looked indifferent. But, with the\n",
      "womanly and courtierlike quickness and tact habitual to her, <span class=\"green\">Anna\n",
      "Pavlovna</span> wished both to rebuke him (for daring to speak he had done of\n",
      "a man recommended to <span class=\"green\">the Empress</span>) and at the same time to console him,\n",
      "so she said:\n",
      "<p></p>\n",
      "\"<span class=\"red\">Now about your family. Do you know that since your daughter came\n",
      "out everyone has been enraptured by her? They say she is amazingly\n",
      "beautiful.</span>\"\n",
      "<p></p>\n",
      "<span class=\"green\">The prince</span> bowed to signify his respect and gratitude.\n",
      "<p></p>\n",
      "\"<span class=\"red\">I often think,</span>\" she continued after a short pause, drawing nearer\n",
      "to the prince and smiling amiably at him as if to show that\n",
      "political and social topics were ended and the time had come for\n",
      "intimate conversation- \"<span class=\"red\">I often think how unfairly sometimes the\n",
      "joys of life are distributed. Why has fate given you two such splendid\n",
      "children? I don't speak of <span class=\"green\">Anatole</span>, your youngest. I don't like\n",
      "him,</span>\" she added in a tone admitting of no rejoinder and raising her\n",
      "eyebrows. \"<span class=\"red\">Two such charming children. And really you appreciate\n",
      "them less than anyone, and so you don't deserve to have them.</span>\"\n",
      "<p></p>\n",
      "And she smiled her ecstatic smile.\n",
      "<p></p>\n",
      "\"<span class=\"red\">I can't help it,</span>\" said <span class=\"green\">the prince</span>. \"<span class=\"red\">Lavater would have said I\n",
      "lack the bump of paternity.</span>\"\n",
      "<p></p>\n",
      "\"<span class=\"red\">Don't joke; I mean to have a serious talk with you. Do you know I\n",
      "am dissatisfied with your younger son? Between ourselves</span>\" (and her\n",
      "face assumed its melancholy expression), \"<span class=\"red\">he was mentioned at Her\n",
      "Majesty's and you were pitied....</span>\"\n",
      "<p></p>\n",
      "<span class=\"green\">The prince</span> answered nothing, but she looked at him significantly,\n",
      "awaiting a reply. He frowned.\n",
      "<p></p>\n",
      "\"<span class=\"red\">What would you have me do?</span>\" he said at last. \"<span class=\"red\">You know I did all\n",
      "a father could for their education, and they have both turned out\n",
      "fools. Hippolyte is at least a quiet fool, but Anatole is an active\n",
      "one. That is the only difference between them.</span>\" He said this smiling\n",
      "in a way more natural and animated than usual, so that the wrinkles\n",
      "round his mouth very clearly revealed something unexpectedly coarse\n",
      "and unpleasant.\n",
      "<p></p>\n",
      "\"<span class=\"red\">And why are children born to such men as you? If you were not a\n",
      "father there would be nothing I could reproach you with,</span>\" said <span class=\"green\">Anna\n",
      "Pavlovna</span>, looking up pensively.\n",
      "<p></p>\n",
      "\"<span class=\"red\">I am your faithful slave and to you alone I can confess that my\n",
      "children are the bane of my life. It is the cross I have to bear. That\n",
      "is how I explain it to myself. It can't be helped!</span>\"\n",
      "<p></p>\n",
      "He said no more, but expressed his resignation to cruel fate by a\n",
      "gesture. <span class=\"green\">Anna Pavlovna</span> meditated.\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "# 전쟁과 평화\n",
    "\n",
    "url = 'http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "html = requests.get(url).text\n",
    "bs = BeautifulSoup(html,'html.parser')\n",
    "print(bs.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6f2427e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.1 : \n",
      " Anna\n",
      "Pavlovna Scherer \n",
      "\n",
      "No.2 : \n",
      " Empress Marya\n",
      "Fedorovna \n",
      "\n",
      "No.3 : \n",
      " Prince Vasili Kuragin \n",
      "\n",
      "No.4 : \n",
      " Anna Pavlovna \n",
      "\n",
      "No.5 : \n",
      " St. Petersburg \n",
      "\n",
      "No.6 : \n",
      " the prince \n",
      "\n",
      "No.7 : \n",
      " Anna Pavlovna \n",
      "\n",
      "No.8 : \n",
      " Anna Pavlovna \n",
      "\n",
      "No.9 : \n",
      " the prince \n",
      "\n",
      "No.10 : \n",
      " the prince \n",
      "\n",
      "No.11 : \n",
      " the prince \n",
      "\n",
      "No.12 : \n",
      " Prince Vasili \n",
      "\n",
      "No.13 : \n",
      " Anna Pavlovna \n",
      "\n",
      "No.14 : \n",
      " Anna Pavlovna \n",
      "\n",
      "No.15 : \n",
      " the prince \n",
      "\n",
      "No.16 : \n",
      " Wintzingerode \n",
      "\n",
      "No.17 : \n",
      " King of Prussia \n",
      "\n",
      "No.18 : \n",
      " le Vicomte de Mortemart \n",
      "\n",
      "No.19 : \n",
      " Montmorencys \n",
      "\n",
      "No.20 : \n",
      " Rohans \n",
      "\n",
      "No.21 : \n",
      " Abbe Morio \n",
      "\n",
      "No.22 : \n",
      " the Emperor \n",
      "\n",
      "No.23 : \n",
      " the prince \n",
      "\n",
      "No.24 : \n",
      " Prince Vasili \n",
      "\n",
      "No.25 : \n",
      " Dowager Empress Marya Fedorovna \n",
      "\n",
      "No.26 : \n",
      " the baron \n",
      "\n",
      "No.27 : \n",
      " Anna Pavlovna \n",
      "\n",
      "No.28 : \n",
      " the Empress \n",
      "\n",
      "No.29 : \n",
      " the Empress \n",
      "\n",
      "No.30 : \n",
      " Anna Pavlovna's \n",
      "\n",
      "No.31 : \n",
      " Her Majesty \n",
      "\n",
      "No.32 : \n",
      " Baron\n",
      "Funke \n",
      "\n",
      "No.33 : \n",
      " The prince \n",
      "\n",
      "No.34 : \n",
      " Anna\n",
      "Pavlovna \n",
      "\n",
      "No.35 : \n",
      " the Empress \n",
      "\n",
      "No.36 : \n",
      " The prince \n",
      "\n",
      "No.37 : \n",
      " Anatole \n",
      "\n",
      "No.38 : \n",
      " the prince \n",
      "\n",
      "No.39 : \n",
      " The prince \n",
      "\n",
      "No.40 : \n",
      " Anna\n",
      "Pavlovna \n",
      "\n",
      "No.41 : \n",
      " Anna Pavlovna \n",
      "\n"
     ]
    }
   ],
   "source": [
    "d1 = bs.find(id='text')\n",
    "# print(d1.text)\n",
    "d2 = bs.findAll('span',{'class':{'green'}})\n",
    "for i,d in enumerate(d2):\n",
    "    print(f'No.{i+1} : \\n {d.text}','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "037fe70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abbe Morio',\n",
       " 'Anatole',\n",
       " 'Anna Pavlovna',\n",
       " 'Anna Pavlovna Scherer',\n",
       " \"Anna Pavlovna's\",\n",
       " 'Baron Funke',\n",
       " 'Dowager Empress Marya Fedorovna',\n",
       " 'Empress Marya Fedorovna',\n",
       " 'Her Majesty',\n",
       " 'King of Prussia',\n",
       " 'Montmorencys',\n",
       " 'Prince Vasili',\n",
       " 'Prince Vasili Kuragin',\n",
       " 'Rohans',\n",
       " 'St. Petersburg',\n",
       " 'The prince',\n",
       " 'Wintzingerode',\n",
       " 'le Vicomte de Mortemart',\n",
       " 'the Emperor',\n",
       " 'the Empress',\n",
       " 'the baron',\n",
       " 'the prince'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q. 전쟁과 평화에 등장하는 모든 고유명사를 출력하세요.\n",
    "url = 'http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "html = requests.get(url).text\n",
    "bs = BeautifulSoup(html,'html.parser')\n",
    "list_a = bs.findAll(class_='green')\n",
    "li1 = []\n",
    "for i in list_a:\n",
    "    i = i.text\n",
    "    li1.append(re.sub('\\n',' ',i))\n",
    "li = set(li1)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "be579a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abbe Morio',\n",
       " 'Anatole',\n",
       " 'Anna Pavlovna',\n",
       " 'Anna Pavlovna Scherer',\n",
       " 'Baron Funke',\n",
       " 'Dowager Empress Marya Fedorovna',\n",
       " 'Empress Marya Fedorovna',\n",
       " 'King of Prussia',\n",
       " 'Montmorencys',\n",
       " 'Prince Vasili',\n",
       " 'Prince Vasili Kuragin',\n",
       " 'Rohans',\n",
       " 'St. Petersburg',\n",
       " 'Wintzingerode',\n",
       " 'le Vicomte de Mortemart'}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "html = requests.get(url).text\n",
    "bs = BeautifulSoup(html,'html.parser')\n",
    "list_a = bs.findAll(class_='green')\n",
    "li1 = []\n",
    "for i in list_a:\n",
    "    i = i.text\n",
    "    if 'The' not in i and 'the' not in i and 'Her' not in i and \"'s\" not in i:\n",
    "        li1.append(re.sub('\\n',' ',i))\n",
    "    else: pass\n",
    "li = set(li1)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1865c5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna Pavlovna Scherer\n",
      "Empress Marya Fedorovna\n",
      "Prince Vasili Kuragin\n",
      "Anna Pavlovna\n",
      "St. Petersburg\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "Prince Vasili\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n",
      "Wintzingerode\n",
      "King of Prussia\n",
      "le Vicomte de Mortemart\n",
      "Montmorencys\n",
      "Rohans\n",
      "Abbe Morio\n",
      "Prince Vasili\n",
      "Dowager Empress Marya Fedorovna\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna's\n",
      "Baron Funke\n",
      "Anna Pavlovna\n",
      "Anatole\n",
      "Anna Pavlovna\n",
      "Anna Pavlovna\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.pythonscraping.com/pages/warandpeace.html'\n",
    "url_req = requests.get(url).text\n",
    "bs = BeautifulSoup(url_req,'html.parser')\n",
    "d2 = bs.findAll('span',{'class':'green'})\n",
    "for i in d2:\n",
    "    i = i.text\n",
    "    if 'the' not in i and 'The' not in i and 'Her' not in i:\n",
    "        print(i.replace('\\n',' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8ff468c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../img/gifts/logo.jpg\n",
      "../img/gifts/img1.jpg\n",
      "../img/gifts/img2.jpg\n",
      "../img/gifts/img3.jpg\n",
      "../img/gifts/img4.jpg\n",
      "../img/gifts/img6.jpg\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.pythonscraping.com/pages/page3.html'\n",
    "html = requests.get(url).text\n",
    "bs = BeautifulSoup(html,'html.parser')\n",
    "lists = bs.findAll('img')\n",
    "for i in lists:\n",
    "    print(i.get('src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d4ca253b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"excitingNote\">Now with super-colorful bell peppers!</span>,\n",
       " <span class=\"excitingNote\">8 entire dolls per set! Octuple the presents!</span>,\n",
       " <span class=\"excitingNote\">Also hand-painted by trained monkeys!</span>,\n",
       " <span class=\"excitingNote\">Or maybe he's only resting?</span>,\n",
       " <span class=\"excitingNote\">Keep your friends guessing!</span>]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lambda를 이용\n",
    "spans = bs.findAll('span')\n",
    "list(spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8c1efb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"excitingNote\">Or maybe he's only resting?</span>]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs.find_all(lambda tag : tag.get_text() == \"Or maybe he's only resting?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e2daa179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tag.prettify of <ul id=\"bible\">\n",
      "<li id=\"ge\">Genesis</li>\n",
      "<li id=\"ex\">Exodus</li>\n",
      "<li id=\"le\">Leviticus</li>\n",
      "<li id=\"nu\">Numbers</li>\n",
      "<li id=\"de\">Deuteronomy</li>\n",
      "</ul>>\n"
     ]
    }
   ],
   "source": [
    "fp = open(\"books.html\", encoding='utf-8')\n",
    "soup = BeautifulSoup(fp,'html.parser')\n",
    "print(soup.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "f1ac9d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n"
     ]
    }
   ],
   "source": [
    "print(soup.find(id='nu').text)\n",
    "print(soup.find(lambda tag : tag.get_text() == \"Numbers\").text)\n",
    "print(soup.find(text = 'Numbers'))\n",
    "print(soup.select_one('#nu').text)\n",
    "print(soup.findAll('li',id='nu')[0].text)\n",
    "print(soup.findAll('li')[3].text)\n",
    "print(soup.select('li')[3].text)\n",
    "print(list(soup.find('ul').children)[7].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "da46f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n",
      "Numbers\n"
     ]
    }
   ],
   "source": [
    "sel = lambda q : print(soup.select_one(q).string)\n",
    "sel('#nu')\n",
    "sel('li#nu')\n",
    "sel('ul > li#nu')\n",
    "sel('#bible #nu')\n",
    "sel('#bible > #nu')\n",
    "sel('ul > #nu')\n",
    "sel('ul#bible > li#nu')\n",
    "sel('li[id=\"nu\"]')\n",
    "sel('li:nth-of-type(4)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aeb129",
   "metadata": {},
   "source": [
    "#### urllib 모듈이란 : 파이썬의 표준 모듈로서 URL을 다루기 위한 모듈 패키지\n",
    "- 설치가 필요하지 않고 import urllib으로 활용\n",
    "- requests 모듈과 마찬가지로 URL과 관련된 여러가지 기능들을 제공(하위 모듈)\n",
    "    - request : URL을 열고 읽는 모듈(HTTP 요청)\n",
    "    - error : request 모듈에서 발생하는 에러들을 포함하는 모듈\n",
    "    - parse : URL을 파싱하는 모듈(URL 해석 및 조작)\n",
    "    - robots.txt : 파일을 파싱하는 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a621693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<urllib.request.Request object at 0x00000180B32EE6A0>\n",
      "http://www.naver.com\n",
      "http\n",
      "www.naver.com\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "\n",
    "url = 'http://www.naver.com'\n",
    "request = urllib.request.Request(url)\n",
    "print(request)\n",
    "print(request.full_url)\n",
    "print(request.type)\n",
    "print(request.host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e2359cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x00000180B32EE310>\n",
      "<bound method HTTPResponse.geturl of <http.client.HTTPResponse object at 0x00000180B32EE310>>\n",
      "[('Server', 'NWS'), ('Date', 'Fri, 11 Feb 2022 00:37:28 GMT'), ('Content-Type', 'text/html; charset=UTF-8'), ('Transfer-Encoding', 'chunked'), ('Connection', 'close'), ('Set-Cookie', 'PM_CK_loc=5c0319f8b9320abe3a1394e11fd74a59bfa71ddb9ac23dd05a5645a7b49350ff; Expires=Sat, 12 Feb 2022 00:37:28 GMT; Path=/; HttpOnly'), ('Cache-Control', 'no-cache, no-store, must-revalidate'), ('Pragma', 'no-cache'), ('P3P', 'CP=\"CAO DSP CURa ADMa TAIa PSAa OUR LAW STP PHY ONL UNI PUR FIN COM NAV INT DEM STA PRE\"'), ('X-Frame-Options', 'DENY'), ('X-XSS-Protection', '1; mode=block'), ('Strict-Transport-Security', 'max-age=63072000; includeSubdomains'), ('Referrer-Policy', 'unsafe-url')]\n"
     ]
    }
   ],
   "source": [
    "response1 = urllib.request.urlopen(request)\n",
    "print(response1)\n",
    "print(response1.geturl)\n",
    "print(response1.getheaders())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1eb6667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<!doctype html>                          <html lang=\"ko\" data-dark=\"false\"> <head> <meta charset=\"u'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read() : 인자로 전달한 숫자만큼 데이터를 읽음\n",
    "response2 = urllib.request.urlopen(url)\n",
    "response2.read(100).decode('utf-8') # requests.get(url).text 와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39019e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n<!doctype html>                          <html lang=\"ko\" data-dark=\"false\"> <head> <meta charset=\"u'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(url).text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4419b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('img.png', <http.client.HTTPMessage at 0x180b22f6eb0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# urllib.request.urlretrieve() : 웹상의 이미지 저장\n",
    "import urllib.request\n",
    "img_src = 'https://images.unsplash.com/photo-1644458729023-aacfb3f92996?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxlZGl0b3JpYWwtZmVlZHw1fHx8ZW58MHx8fHw%3D&auto=format&fit=crop&w=500&q=60'\n",
    "new_name = 'img.png'\n",
    "urllib.request.urlretrieve(img_src,new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "db8b24e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='https', netloc='section.blog.naver.com', path='/Search/Post.naver', params='', query='pageNo=1&rangeType=ALL&orderBy=sim&keyword=ai', fragment='') \n",
      "\n",
      "https\n",
      "https \n",
      "\n",
      "section.blog.naver.com\n",
      "section.blog.naver.com \n",
      "\n",
      "/Search/Post.naver\n",
      "/Search/Post.naver \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "pageNo=1&rangeType=ALL&orderBy=sim&keyword=ai\n",
      "pageNo=1&rangeType=ALL&orderBy=sim&keyword=ai \n",
      "\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 단순한 패턴을 읽을 때에는 복잡한 정규표현식보다는 간단한 parse 모듈을 사용\n",
    "# urllib.parse : URL을 6개로 분리하여 반환\n",
    "import urllib\n",
    "url = 'https://section.blog.naver.com/Search/Post.naver?pageNo=1&rangeType=ALL&orderBy=sim&keyword=ai'\n",
    "\n",
    "parse = urllib.parse.urlparse(url)\n",
    "print(parse,'\\n')\n",
    "print(parse[0])\n",
    "print(parse.scheme,'\\n')\n",
    "print(parse[1])\n",
    "print(parse.netloc,'\\n')\n",
    "print(parse[2])\n",
    "print(parse.path,'\\n')\n",
    "print(parse[3])\n",
    "print(parse.params,'\\n')\n",
    "print(parse[4])\n",
    "print(parse.query,'\\n')\n",
    "print(parse[5])\n",
    "print(parse.fragment,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d97924e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='https', netloc='blog.naver.com', path='/koreatech91', params='a=1', query='b=2', fragment='b')\n",
      "https://blog.daum.net/koreatech91;a=1?b=2#b\n"
     ]
    }
   ],
   "source": [
    "# urllib.parse.urlunparse() , urllib.parse.urlunsplit()\n",
    "# 튜플(변경 불가능)로 반환되기 때문에 리스트(변경 가능)로 병경하여 활용\n",
    "parse = urllib.parse.urlparse('https://blog.naver.com/koreatech91;a=1?b=2#b')\n",
    "print(parse)\n",
    "parse = list(parse)\n",
    "parse[1] = 'blog.daum.net'\n",
    "parse\n",
    "unparse = urllib.parse.urlunparse(parse)\n",
    "print(unparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8255c1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b=2\n",
      "{'b': ['2']} <class 'dict'>\n",
      "[('b', '2')] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# parse_qs()\n",
    "# 쿼리를 파싱해서 사전(qs) 밑 리스트(qs)로 반환, 쿼리를 변경하여 요청시 활용\n",
    "parse = urllib.parse.urlparse('https://blog.naver.com/koreatech91;a=1?b=2#b')\n",
    "print(parse.query)\n",
    "qs = urllib.parse.parse_qs(parse.query)\n",
    "print(qs, type(qs))\n",
    "qsl = urllib.parse.parse_qsl(parse.query)\n",
    "print(qsl,type(qsl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07b59d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://naver.com/a/c\n",
      "https://naver.com/c\n",
      "https://naver.com/a/b/c\n",
      "https://naver.com/c\n"
     ]
    }
   ],
   "source": [
    "# urljoin(a,b) : a 와 b url을 합쳐주는 기능. '/'에 따라 url 주소가 달라짐\n",
    "url = 'https://naver.com/a/b'\n",
    "print(urllib.parse.urljoin(url,'c'))\n",
    "print(urllib.parse.urljoin(url,'/c'))\n",
    "\n",
    "url = 'https://naver.com/a/b/'\n",
    "print(urllib.parse.urljoin(url,'c'))\n",
    "print(urllib.parse.urljoin(url,'/c'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0a0997e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%ED%8C%8C%EC%9D%B4%EC%8D%AC\n",
      "파이썬\n"
     ]
    }
   ],
   "source": [
    "# quote(), unpuote() : 아스키코드가 아닌 퍼센트 인코딩으로 변환\n",
    "# 퍼센트 인코딩은 url에 문자를 표현하는 문자 인코딩 방법\n",
    "# url에 한글이 섞이면 오류 발생\n",
    "\n",
    "print(urllib.parse.quote('파이썬'))\n",
    "print(urllib.parse.unquote('%ED%8C%8C%EC%9D%B4%EC%8D%AC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b6b7b00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html> <html lang=\"ko\"> <head> <meta charset=\"utf-8\"> <meta name=\"referrer\" content=\"always\n"
     ]
    }
   ],
   "source": [
    "# url = 'https://search.naver.com/search.naver?query=\"파이썬\"'\n",
    "url = 'https://search.naver.com/search.naver?query=\"%ED%8C%8C%EC%9D%B4%EC%8D%AC\"'\n",
    "\n",
    "response = urllib.request.urlopen(url)\n",
    "byte_data = response.read(100)\n",
    "text_data = byte_data.decode('utf-8')\n",
    "print(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a0f2aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홈페이지를 로컬에 파일로 저장\n",
    "request = urllib.request.Request('http://www.naver.com')\n",
    "data = urllib.request.urlopen(request).read()\n",
    "f = open('pc.html','wb')\n",
    "f.write(data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "13771caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<!doctype html>                          <html lang=\"ko\" data-dark=\"false\"> <head> <meta charset=\"u\n"
     ]
    }
   ],
   "source": [
    "with open('pc.html','rb') as f:\n",
    "    data = f.read(100).decode('utf-8')\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "141449a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html> <html lang=\"ko\"> <head> <meta charset=\"utf-8\"> <meta name=\"referrer\" content=\"always\">  <meta name=\"format-detection\" content=\"telephone=no,address=no,email=no\"> <meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=2.0\"> <meta property=\"og:title\" content=\"파이썬 : 네이버 통합검색\"/> <meta property=\"og:image\" content=\"https://ssl.pstatic.net/ss\n",
      "<!doctype html> <html lang=\"ko\"> <head> <meta charset=\"utf-8\"> <meta name=\"referrer\" content=\"always\">  <meta name=\"format-detection\" content=\"telephone=no,address=no,email=no\"> <meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=2.0\"> <meta property=\"og:title\" content=\"웹 크롤링 : 네이버 통합검색\"/> <meta property=\"og:image\" content=\"https://ssl.pstatic.ne\n",
      "<!doctype html> <html lang=\"ko\"> <head> <meta charset=\"utf-8\"> <meta name=\"referrer\" content=\"always\">  <meta name=\"format-detection\" content=\"telephone=no,address=no,email=no\"> <meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=2.0\"> <meta property=\"og:title\" content=\"빅데이터 : 네이버 통합검색\"/> <meta property=\"og:image\" content=\"https://ssl.pstatic.net\n",
      "<!doctype html> <html lang=\"ko\"> <head> <meta charset=\"utf-8\"> <meta name=\"referrer\" content=\"always\">  <meta name=\"format-detection\" content=\"telephone=no,address=no,email=no\"> <meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=2.0\"> <meta property=\"og:title\" content=\"python : 네이버 통합검색\"/> <meta property=\"og:image\" content=\"https://ssl.pstatic.net/sstat\n"
     ]
    }
   ],
   "source": [
    "query_list = ['파이썬','웹 크롤링','빅데이터','python']\n",
    "url = 'https://search.naver.com/search.naver?query='\n",
    "for i in query_list:\n",
    "    new_url = url + urllib.parse.quote(i)\n",
    "    response_urllib = urllib.request.urlopen(new_url)\n",
    "    byte_data = response_urllib.read(400)\n",
    "    text_data = byte_data.decode('utf-8')\n",
    "    print(text_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
