{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 기반 빅데이터 서비스 솔루션 개발 전문 과정\n",
    "\n",
    "#### 교과목명 : 머신러닝알고리즘 이해 및 활용\n",
    "- 평가일 : 03.10\n",
    "- 성명 : 권혁종\n",
    "- 점수 : 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. iris data를 불러와서 아래 사항을 수행하세요.(15점)\n",
    "\n",
    "- 결정트리 모델을 시각화하고 주요한 인사이트를 기술하세요.(tree.plot_tree or tree.export_graphviz 이용)\n",
    "- Feature importance를 추출하고 시각화하세요. 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"557pt\" height=\"373pt\"\n viewBox=\"0.00 0.00 557.00 373.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 369)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-369 553,-369 553,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"275.5,-365 107.5,-365 107.5,-297 275.5,-297 275.5,-365\"/>\n<text text-anchor=\"middle\" x=\"191.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 0.75</text>\n<text text-anchor=\"middle\" x=\"191.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.666</text>\n<text text-anchor=\"middle\" x=\"191.5\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\n<text text-anchor=\"middle\" x=\"191.5\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [42, 39, 39]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"169,-253.5 48,-253.5 48,-200.5 169,-200.5 169,-253.5\"/>\n<text text-anchor=\"middle\" x=\"108.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"108.5\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n<text text-anchor=\"middle\" x=\"108.5\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [42, 0, 0]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M164.55,-296.88C155.33,-285.56 145.02,-272.88 135.78,-261.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"138.29,-259.07 129.27,-253.52 132.86,-263.49 138.29,-259.07\"/>\n<text text-anchor=\"middle\" x=\"126.71\" y=\"-274.69\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"361.5,-261 187.5,-261 187.5,-193 361.5,-193 361.5,-261\"/>\n<text text-anchor=\"middle\" x=\"274.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) &lt;= 4.75</text>\n<text text-anchor=\"middle\" x=\"274.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"middle\" x=\"274.5\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 78</text>\n<text text-anchor=\"middle\" x=\"274.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 39, 39]</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M218.45,-296.88C225.62,-288.07 233.46,-278.43 240.95,-269.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"243.81,-271.26 247.4,-261.3 238.38,-266.85 243.81,-271.26\"/>\n<text text-anchor=\"middle\" x=\"249.96\" y=\"-282.47\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"265.5,-157 97.5,-157 97.5,-89 265.5,-89 265.5,-157\"/>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.65</text>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.054</text>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 36</text>\n<text text-anchor=\"middle\" x=\"181.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 35, 1]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M244.31,-192.88C236.18,-183.98 227.3,-174.24 218.84,-164.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"221.19,-162.33 211.86,-157.3 216.01,-167.05 221.19,-162.33\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"451.5,-157 283.5,-157 283.5,-89 451.5,-89 451.5,-157\"/>\n<text text-anchor=\"middle\" x=\"367.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.75</text>\n<text text-anchor=\"middle\" x=\"367.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.172</text>\n<text text-anchor=\"middle\" x=\"367.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n<text text-anchor=\"middle\" x=\"367.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4, 38]</text>\n</g>\n<!-- 2&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M304.69,-192.88C312.82,-183.98 321.7,-174.24 330.16,-164.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"332.99,-167.05 337.14,-157.3 327.81,-162.33 332.99,-167.05\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"121,-53 0,-53 0,0 121,0 121,-53\"/>\n<text text-anchor=\"middle\" x=\"60.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"60.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"middle\" x=\"60.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 35, 0]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M139.18,-88.95C127,-79.43 113.73,-69.07 101.62,-59.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"103.49,-56.63 93.45,-53.24 99.18,-62.15 103.49,-56.63\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"252,-53 139,-53 139,0 252,0 252,-53\"/>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"middle\" x=\"195.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 0, 1]</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M186.4,-88.95C187.63,-80.62 188.96,-71.65 190.21,-63.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"193.68,-63.64 191.69,-53.24 186.76,-62.62 193.68,-63.64\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"410,-53 297,-53 297,0 410,0 410,-53\"/>\n<text text-anchor=\"middle\" x=\"353.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n<text text-anchor=\"middle\" x=\"353.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"middle\" x=\"353.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3, 4]</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M362.6,-88.95C361.37,-80.62 360.04,-71.65 358.79,-63.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"362.24,-62.62 357.31,-53.24 355.32,-63.64 362.24,-62.62\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"black\" points=\"549,-53 428,-53 428,0 549,0 549,-53\"/>\n<text text-anchor=\"middle\" x=\"488.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.056</text>\n<text text-anchor=\"middle\" x=\"488.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"middle\" x=\"488.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 34]</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M409.82,-88.95C422,-79.43 435.27,-69.07 447.38,-59.62\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"449.82,-62.15 455.55,-53.24 445.51,-56.63 449.82,-62.15\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.sources.Source at 0x1d9ef7020d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "\n",
    "dataset = load_iris()\n",
    "df_iris = pd.DataFrame(data=dataset.data,columns = dataset.feature_names)\n",
    "y = dataset.target\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state =132,max_depth=3)\n",
    "X_train,X_test,y_train,y_test = train_test_split(df_iris,y,test_size = 0.2,random_state=135)\n",
    "dt_clf.fit(X_train,y_train)\n",
    "\n",
    "data = tree.export_graphviz(decision_tree=dt_clf,\n",
    "                            feature_names=dataset.feature_names)\n",
    "graphviz.Source(data)\n",
    "\n",
    "# petal의 너비와 길이로 3개의 품종이 대부분 가려진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        0.        0.3998127 0.6001873]\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "print(dt_clf.feature_importances_)\n",
    "print(dataset.feature_names)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(dt_clf.feature_importances_,dataset.feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2~Q3. 'dataset/creditcard.csv'를 불러와서 신용카드 사기 검출 분류문제를 아래와 같이 수행하세요(10점) 10\n",
    "- 로지스틱 리그레션을 적용한 모델 학습 및 사용자 함수를 이용하여 평가\n",
    "    - 인자로 입력받은 DataFrame을 복사한 뒤 Time 칼럼만 삭제하고 복사된 df 반환하는 사용자 함수 생성\n",
    "    - 사전 데이터 가공 후 학습과 테스트 데이터 세트를 반환하는 함수(테스트 사이즈 0.3)\n",
    "    - 오차행렬, 정확도, 정밀도, 재현율, f1, AUC 평가 함수\n",
    "    \n",
    "- 인자로 사이킷런의 Estimator 객체와 학습/테스트 데이터 세트를 입력 받아서  학습/예측/평가 수행\n",
    "    - 사용자 함수를 사용하여 LightGBM으로 모델을 학습한 뒤 별도의 테스트 데이터 세트에서 예측 평가를 수행. 단, n_estimators=1000, num_leaves=64 적용<br>  ※ 레이블 값이 극도로 불균형한 분포를 가지고 있는 경우 boost_from_average=False로 파라미터 설정(default=True). default 설정은 재현율, AUC 성능을 매우 크게 저하시킴\n",
    "    - 넘파이의 np.log1p( )를 이용하여 Amount를 로그 변환하는하는 사용자 함수 생성\n",
    "    - Amount를 로그 변환 후 로지스틱 회귀 및 LightGBM 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../bigdatafile/creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
    "def timedrop(df):\n",
    "    df1 = df.drop('Time',axis=1)\n",
    "    return df1\n",
    "def datasplit(df):\n",
    "    df = timedrop(df)\n",
    "    X = df.drop('Class',axis=1)\n",
    "    y = df['Class']\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 123)\n",
    "    return X_train,X_test,y_train,y_test\n",
    "def scores(y_test,pred=None,pred_proba=None):\n",
    "    con = confusion_matrix(y_test,pred)\n",
    "    acc = accuracy_score(y_test,pred)\n",
    "    pre = precision_score(y_test,pred)\n",
    "    rec = recall_score(y_test,pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    roc = roc_auc_score(y_test,pred_proba)\n",
    "    print(f'혼동행렬 : \\n {con} \\n정확도 : {acc:0.4f}, 정밀도 : {pre:0.4f}, 재현율 : {rec:0.4f}, f1_score : {f1:0.4f}, roc_auc : {roc:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼동행렬 : \n",
      " [[85262    21]\n",
      " [   59   101]] \n",
      "정확도 : 0.9991, 정밀도 : 0.8279, 재현율 : 0.6312, f1_score : 0.7163, roc_auc : 0.9794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "X_train,X_test,y_train,y_test = datasplit(df)\n",
    "lr.fit(X_train,y_train)\n",
    "pred = lr.predict(X_test)\n",
    "pred_proba = lr.predict_proba(X_test)[:,1]\n",
    "scores(y_test,pred,pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인자로 사이킷런의 Estimator 객체와 학습/테스트 데이터 세트를 입력 받아서  학습/예측/평가 수행\n",
    "    - 사용자 함수를 사용하여 LightGBM으로 모델을 학습한 뒤 별도의 테스트 데이터 세트에서 예측 평가를 수행. 단, n_estimators=1000, num_leaves=64 적용<br>  ※ 레이블 값이 극도로 불균형한 분포를 가지고 있는 경우 boost_from_average=False로 파라미터 설정(default=True). default 설정은 재현율, AUC 성능을 매우 크게 저하시킴\n",
    "    - 넘파이의 np.log1p( )를 이용하여 Amount를 로그 변환하는하는 사용자 함수 생성\n",
    "    - Amount를 로그 변환 후 로지스틱 회귀 및 LightGBM 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "def lgbm_score(Estimator,X_train,X_test,y_train,y_test):\n",
    "    lgbm = Estimator(n_estimators=1000,num_leaves=64,boost_from_average=False)\n",
    "    lgbm.fit(X_train,y_train,early_stopping_rounds=100,eval_set=[(X_test,y_test)],eval_metric='logloss')\n",
    "    pred = lgbm.predict(X_test)\n",
    "    pred_proba = lgbm.predict_proba(X_test)[:,1]\n",
    "    scores(y_test,pred,pred_proba)\n",
    "def lr_score(X_train,X_test,y_train,y_test):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train,y_train)\n",
    "    pred = lr.predict(X_test)\n",
    "    pred_proba = lr.predict_proba(X_test)[:,1]\n",
    "    scores(y_test,pred,pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.598338\n",
      "[2]\tvalid_0's binary_logloss: 0.520691\n",
      "[3]\tvalid_0's binary_logloss: 0.455945\n",
      "[4]\tvalid_0's binary_logloss: 0.401208\n",
      "[5]\tvalid_0's binary_logloss: 0.354459\n",
      "[6]\tvalid_0's binary_logloss: 0.314194\n",
      "[7]\tvalid_0's binary_logloss: 0.279262\n",
      "[8]\tvalid_0's binary_logloss: 0.248795\n",
      "[9]\tvalid_0's binary_logloss: 0.222103\n",
      "[10]\tvalid_0's binary_logloss: 0.198622\n",
      "[11]\tvalid_0's binary_logloss: 0.177893\n",
      "[12]\tvalid_0's binary_logloss: 0.159544\n",
      "[13]\tvalid_0's binary_logloss: 0.143267\n",
      "[14]\tvalid_0's binary_logloss: 0.128787\n",
      "[15]\tvalid_0's binary_logloss: 0.11588\n",
      "[16]\tvalid_0's binary_logloss: 0.10436\n",
      "[17]\tvalid_0's binary_logloss: 0.0940656\n",
      "[18]\tvalid_0's binary_logloss: 0.0848588\n",
      "[19]\tvalid_0's binary_logloss: 0.0766139\n",
      "[20]\tvalid_0's binary_logloss: 0.0692152\n",
      "[21]\tvalid_0's binary_logloss: 0.0625759\n",
      "[22]\tvalid_0's binary_logloss: 0.0566073\n",
      "[23]\tvalid_0's binary_logloss: 0.051248\n",
      "[24]\tvalid_0's binary_logloss: 0.0464302\n",
      "[25]\tvalid_0's binary_logloss: 0.0420921\n",
      "[26]\tvalid_0's binary_logloss: 0.0381918\n",
      "[27]\tvalid_0's binary_logloss: 0.0346747\n",
      "[28]\tvalid_0's binary_logloss: 0.031509\n",
      "[29]\tvalid_0's binary_logloss: 0.0286525\n",
      "[30]\tvalid_0's binary_logloss: 0.0260808\n",
      "[31]\tvalid_0's binary_logloss: 0.0237622\n",
      "[32]\tvalid_0's binary_logloss: 0.0216637\n",
      "[33]\tvalid_0's binary_logloss: 0.0197688\n",
      "[34]\tvalid_0's binary_logloss: 0.0180547\n",
      "[35]\tvalid_0's binary_logloss: 0.0165123\n",
      "[36]\tvalid_0's binary_logloss: 0.0151293\n",
      "[37]\tvalid_0's binary_logloss: 0.0138716\n",
      "[38]\tvalid_0's binary_logloss: 0.0127407\n",
      "[39]\tvalid_0's binary_logloss: 0.0117165\n",
      "[40]\tvalid_0's binary_logloss: 0.0107929\n",
      "[41]\tvalid_0's binary_logloss: 0.00996174\n",
      "[42]\tvalid_0's binary_logloss: 0.00920262\n",
      "[43]\tvalid_0's binary_logloss: 0.0085264\n",
      "[44]\tvalid_0's binary_logloss: 0.0079108\n",
      "[45]\tvalid_0's binary_logloss: 0.00736102\n",
      "[46]\tvalid_0's binary_logloss: 0.0068666\n",
      "[47]\tvalid_0's binary_logloss: 0.00641036\n",
      "[48]\tvalid_0's binary_logloss: 0.00600887\n",
      "[49]\tvalid_0's binary_logloss: 0.0056406\n",
      "[50]\tvalid_0's binary_logloss: 0.00531821\n",
      "[51]\tvalid_0's binary_logloss: 0.00502108\n",
      "[52]\tvalid_0's binary_logloss: 0.00475449\n",
      "[53]\tvalid_0's binary_logloss: 0.00451826\n",
      "[54]\tvalid_0's binary_logloss: 0.00430362\n",
      "[55]\tvalid_0's binary_logloss: 0.00411199\n",
      "[56]\tvalid_0's binary_logloss: 0.00394038\n",
      "[57]\tvalid_0's binary_logloss: 0.00378988\n",
      "[58]\tvalid_0's binary_logloss: 0.00365525\n",
      "[59]\tvalid_0's binary_logloss: 0.00353664\n",
      "[60]\tvalid_0's binary_logloss: 0.00342885\n",
      "[61]\tvalid_0's binary_logloss: 0.00332749\n",
      "[62]\tvalid_0's binary_logloss: 0.00324384\n",
      "[63]\tvalid_0's binary_logloss: 0.00316793\n",
      "[64]\tvalid_0's binary_logloss: 0.0031282\n",
      "[65]\tvalid_0's binary_logloss: 0.00307378\n",
      "[66]\tvalid_0's binary_logloss: 0.00301834\n",
      "[67]\tvalid_0's binary_logloss: 0.0029672\n",
      "[68]\tvalid_0's binary_logloss: 0.0029323\n",
      "[69]\tvalid_0's binary_logloss: 0.00290178\n",
      "[70]\tvalid_0's binary_logloss: 0.0028723\n",
      "[71]\tvalid_0's binary_logloss: 0.00284963\n",
      "[72]\tvalid_0's binary_logloss: 0.00282507\n",
      "[73]\tvalid_0's binary_logloss: 0.00280852\n",
      "[74]\tvalid_0's binary_logloss: 0.00278868\n",
      "[75]\tvalid_0's binary_logloss: 0.00277647\n",
      "[76]\tvalid_0's binary_logloss: 0.00276912\n",
      "[77]\tvalid_0's binary_logloss: 0.00276156\n",
      "[78]\tvalid_0's binary_logloss: 0.00275742\n",
      "[79]\tvalid_0's binary_logloss: 0.00275569\n",
      "[80]\tvalid_0's binary_logloss: 0.0027561\n",
      "[81]\tvalid_0's binary_logloss: 0.00275924\n",
      "[82]\tvalid_0's binary_logloss: 0.00276383\n",
      "[83]\tvalid_0's binary_logloss: 0.0027705\n",
      "[84]\tvalid_0's binary_logloss: 0.00277874\n",
      "[85]\tvalid_0's binary_logloss: 0.00278492\n",
      "[86]\tvalid_0's binary_logloss: 0.00280624\n",
      "[87]\tvalid_0's binary_logloss: 0.00282722\n",
      "[88]\tvalid_0's binary_logloss: 0.0028387\n",
      "[89]\tvalid_0's binary_logloss: 0.00286282\n",
      "[90]\tvalid_0's binary_logloss: 0.00287887\n",
      "[91]\tvalid_0's binary_logloss: 0.00289407\n",
      "[92]\tvalid_0's binary_logloss: 0.00291215\n",
      "[93]\tvalid_0's binary_logloss: 0.00292622\n",
      "[94]\tvalid_0's binary_logloss: 0.00293965\n",
      "[95]\tvalid_0's binary_logloss: 0.00295995\n",
      "[96]\tvalid_0's binary_logloss: 0.00298265\n",
      "[97]\tvalid_0's binary_logloss: 0.00299963\n",
      "[98]\tvalid_0's binary_logloss: 0.00302258\n",
      "[99]\tvalid_0's binary_logloss: 0.00304132\n",
      "[100]\tvalid_0's binary_logloss: 0.00306016\n",
      "[101]\tvalid_0's binary_logloss: 0.00308246\n",
      "[102]\tvalid_0's binary_logloss: 0.00310259\n",
      "[103]\tvalid_0's binary_logloss: 0.0031305\n",
      "[104]\tvalid_0's binary_logloss: 0.00315426\n",
      "[105]\tvalid_0's binary_logloss: 0.00316615\n",
      "[106]\tvalid_0's binary_logloss: 0.0031865\n",
      "[107]\tvalid_0's binary_logloss: 0.0032153\n",
      "[108]\tvalid_0's binary_logloss: 0.00323469\n",
      "[109]\tvalid_0's binary_logloss: 0.0032508\n",
      "[110]\tvalid_0's binary_logloss: 0.00327585\n",
      "[111]\tvalid_0's binary_logloss: 0.00329945\n",
      "[112]\tvalid_0's binary_logloss: 0.00332497\n",
      "[113]\tvalid_0's binary_logloss: 0.00334405\n",
      "[114]\tvalid_0's binary_logloss: 0.00336519\n",
      "[115]\tvalid_0's binary_logloss: 0.00339769\n",
      "[116]\tvalid_0's binary_logloss: 0.00341976\n",
      "[117]\tvalid_0's binary_logloss: 0.00344166\n",
      "[118]\tvalid_0's binary_logloss: 0.00347004\n",
      "[119]\tvalid_0's binary_logloss: 0.00349485\n",
      "[120]\tvalid_0's binary_logloss: 0.00351608\n",
      "[121]\tvalid_0's binary_logloss: 0.00353979\n",
      "[122]\tvalid_0's binary_logloss: 0.00357188\n",
      "[123]\tvalid_0's binary_logloss: 0.00359874\n",
      "[124]\tvalid_0's binary_logloss: 0.00361936\n",
      "[125]\tvalid_0's binary_logloss: 0.0036459\n",
      "[126]\tvalid_0's binary_logloss: 0.00366765\n",
      "[127]\tvalid_0's binary_logloss: 0.00369945\n",
      "[128]\tvalid_0's binary_logloss: 0.00372218\n",
      "[129]\tvalid_0's binary_logloss: 0.00374091\n",
      "[130]\tvalid_0's binary_logloss: 0.00376806\n",
      "[131]\tvalid_0's binary_logloss: 0.00379414\n",
      "[132]\tvalid_0's binary_logloss: 0.0038181\n",
      "[133]\tvalid_0's binary_logloss: 0.00385137\n",
      "[134]\tvalid_0's binary_logloss: 0.00388477\n",
      "[135]\tvalid_0's binary_logloss: 0.00391012\n",
      "[136]\tvalid_0's binary_logloss: 0.00393097\n",
      "[137]\tvalid_0's binary_logloss: 0.00396084\n",
      "[138]\tvalid_0's binary_logloss: 0.00398246\n",
      "[139]\tvalid_0's binary_logloss: 0.00400676\n",
      "[140]\tvalid_0's binary_logloss: 0.00402987\n",
      "[141]\tvalid_0's binary_logloss: 0.00405542\n",
      "[142]\tvalid_0's binary_logloss: 0.00408316\n",
      "[143]\tvalid_0's binary_logloss: 0.0041042\n",
      "[144]\tvalid_0's binary_logloss: 0.00413107\n",
      "[145]\tvalid_0's binary_logloss: 0.00414964\n",
      "[146]\tvalid_0's binary_logloss: 0.00417669\n",
      "[147]\tvalid_0's binary_logloss: 0.004202\n",
      "[148]\tvalid_0's binary_logloss: 0.00421998\n",
      "[149]\tvalid_0's binary_logloss: 0.00424107\n",
      "[150]\tvalid_0's binary_logloss: 0.00425755\n",
      "[151]\tvalid_0's binary_logloss: 0.0042831\n",
      "[152]\tvalid_0's binary_logloss: 0.00430332\n",
      "[153]\tvalid_0's binary_logloss: 0.0043253\n",
      "[154]\tvalid_0's binary_logloss: 0.00434422\n",
      "[155]\tvalid_0's binary_logloss: 0.00436096\n",
      "[156]\tvalid_0's binary_logloss: 0.00437846\n",
      "[157]\tvalid_0's binary_logloss: 0.00440122\n",
      "[158]\tvalid_0's binary_logloss: 0.00442603\n",
      "[159]\tvalid_0's binary_logloss: 0.00444495\n",
      "[160]\tvalid_0's binary_logloss: 0.00445874\n",
      "[161]\tvalid_0's binary_logloss: 0.00446234\n",
      "[162]\tvalid_0's binary_logloss: 0.00448573\n",
      "[163]\tvalid_0's binary_logloss: 0.00449911\n",
      "[164]\tvalid_0's binary_logloss: 0.00450749\n",
      "[165]\tvalid_0's binary_logloss: 0.00452046\n",
      "[166]\tvalid_0's binary_logloss: 0.00452912\n",
      "[167]\tvalid_0's binary_logloss: 0.00454332\n",
      "[168]\tvalid_0's binary_logloss: 0.00455931\n",
      "[169]\tvalid_0's binary_logloss: 0.00457054\n",
      "[170]\tvalid_0's binary_logloss: 0.00458086\n",
      "[171]\tvalid_0's binary_logloss: 0.0045859\n",
      "[172]\tvalid_0's binary_logloss: 0.00459826\n",
      "[173]\tvalid_0's binary_logloss: 0.00460806\n",
      "[174]\tvalid_0's binary_logloss: 0.00461745\n",
      "[175]\tvalid_0's binary_logloss: 0.00463525\n",
      "[176]\tvalid_0's binary_logloss: 0.00464903\n",
      "[177]\tvalid_0's binary_logloss: 0.00466376\n",
      "[178]\tvalid_0's binary_logloss: 0.00467171\n",
      "[179]\tvalid_0's binary_logloss: 0.00468414\n",
      "혼동행렬 : \n",
      " [[85276     7]\n",
      " [   32   128]] \n",
      "정확도 : 0.9995, 정밀도 : 0.9481, 재현율 : 0.8000, f1_score : 0.8678, roc_auc : 0.9566\n"
     ]
    }
   ],
   "source": [
    "lgbm_score(LGBMClassifier,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 넘파이의 np.log1p( )를 이용하여 Amount를 로그 변환하는하는 사용자 함수 생성\n",
    "    - Amount를 로그 변환 후 로지스틱 회귀 및 LightGBM 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼동행렬 : \n",
      " [[85266    17]\n",
      " [   64    96]] \n",
      "정확도 : 0.9991, 정밀도 : 0.8496, 재현율 : 0.6000, f1_score : 0.7033, roc_auc : 0.9774\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def log_amount(df):\n",
    "    df['Amount'] = np.log1p(df['Amount'])\n",
    "    return df\n",
    "df = log_amount(df)\n",
    "X_train,X_test,y_train,y_test = datasplit(df)\n",
    "lr_score(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.598338\n",
      "[2]\tvalid_0's binary_logloss: 0.520691\n",
      "[3]\tvalid_0's binary_logloss: 0.455945\n",
      "[4]\tvalid_0's binary_logloss: 0.401208\n",
      "[5]\tvalid_0's binary_logloss: 0.354459\n",
      "[6]\tvalid_0's binary_logloss: 0.314194\n",
      "[7]\tvalid_0's binary_logloss: 0.279262\n",
      "[8]\tvalid_0's binary_logloss: 0.248795\n",
      "[9]\tvalid_0's binary_logloss: 0.222103\n",
      "[10]\tvalid_0's binary_logloss: 0.198622\n",
      "[11]\tvalid_0's binary_logloss: 0.177893\n",
      "[12]\tvalid_0's binary_logloss: 0.159544\n",
      "[13]\tvalid_0's binary_logloss: 0.143267\n",
      "[14]\tvalid_0's binary_logloss: 0.128787\n",
      "[15]\tvalid_0's binary_logloss: 0.11588\n",
      "[16]\tvalid_0's binary_logloss: 0.10436\n",
      "[17]\tvalid_0's binary_logloss: 0.0940656\n",
      "[18]\tvalid_0's binary_logloss: 0.0848588\n",
      "[19]\tvalid_0's binary_logloss: 0.0766139\n",
      "[20]\tvalid_0's binary_logloss: 0.0692152\n",
      "[21]\tvalid_0's binary_logloss: 0.0625759\n",
      "[22]\tvalid_0's binary_logloss: 0.0566073\n",
      "[23]\tvalid_0's binary_logloss: 0.051248\n",
      "[24]\tvalid_0's binary_logloss: 0.0464302\n",
      "[25]\tvalid_0's binary_logloss: 0.0420921\n",
      "[26]\tvalid_0's binary_logloss: 0.0381918\n",
      "[27]\tvalid_0's binary_logloss: 0.0346747\n",
      "[28]\tvalid_0's binary_logloss: 0.031509\n",
      "[29]\tvalid_0's binary_logloss: 0.0286525\n",
      "[30]\tvalid_0's binary_logloss: 0.0260808\n",
      "[31]\tvalid_0's binary_logloss: 0.0237622\n",
      "[32]\tvalid_0's binary_logloss: 0.0216637\n",
      "[33]\tvalid_0's binary_logloss: 0.0197688\n",
      "[34]\tvalid_0's binary_logloss: 0.0180547\n",
      "[35]\tvalid_0's binary_logloss: 0.0165123\n",
      "[36]\tvalid_0's binary_logloss: 0.0151293\n",
      "[37]\tvalid_0's binary_logloss: 0.0138716\n",
      "[38]\tvalid_0's binary_logloss: 0.0127407\n",
      "[39]\tvalid_0's binary_logloss: 0.0117165\n",
      "[40]\tvalid_0's binary_logloss: 0.0107929\n",
      "[41]\tvalid_0's binary_logloss: 0.00996174\n",
      "[42]\tvalid_0's binary_logloss: 0.00920262\n",
      "[43]\tvalid_0's binary_logloss: 0.0085264\n",
      "[44]\tvalid_0's binary_logloss: 0.0079108\n",
      "[45]\tvalid_0's binary_logloss: 0.00736102\n",
      "[46]\tvalid_0's binary_logloss: 0.0068666\n",
      "[47]\tvalid_0's binary_logloss: 0.00641036\n",
      "[48]\tvalid_0's binary_logloss: 0.00600887\n",
      "[49]\tvalid_0's binary_logloss: 0.0056406\n",
      "[50]\tvalid_0's binary_logloss: 0.00531821\n",
      "[51]\tvalid_0's binary_logloss: 0.00502108\n",
      "[52]\tvalid_0's binary_logloss: 0.00475449\n",
      "[53]\tvalid_0's binary_logloss: 0.00451826\n",
      "[54]\tvalid_0's binary_logloss: 0.00430362\n",
      "[55]\tvalid_0's binary_logloss: 0.00411199\n",
      "[56]\tvalid_0's binary_logloss: 0.00394038\n",
      "[57]\tvalid_0's binary_logloss: 0.00378988\n",
      "[58]\tvalid_0's binary_logloss: 0.00365525\n",
      "[59]\tvalid_0's binary_logloss: 0.00353664\n",
      "[60]\tvalid_0's binary_logloss: 0.00342885\n",
      "[61]\tvalid_0's binary_logloss: 0.00332749\n",
      "[62]\tvalid_0's binary_logloss: 0.00324384\n",
      "[63]\tvalid_0's binary_logloss: 0.00316793\n",
      "[64]\tvalid_0's binary_logloss: 0.0031282\n",
      "[65]\tvalid_0's binary_logloss: 0.00307378\n",
      "[66]\tvalid_0's binary_logloss: 0.00301834\n",
      "[67]\tvalid_0's binary_logloss: 0.0029672\n",
      "[68]\tvalid_0's binary_logloss: 0.0029323\n",
      "[69]\tvalid_0's binary_logloss: 0.00290178\n",
      "[70]\tvalid_0's binary_logloss: 0.0028723\n",
      "[71]\tvalid_0's binary_logloss: 0.00284963\n",
      "[72]\tvalid_0's binary_logloss: 0.00282507\n",
      "[73]\tvalid_0's binary_logloss: 0.00280852\n",
      "[74]\tvalid_0's binary_logloss: 0.00278868\n",
      "[75]\tvalid_0's binary_logloss: 0.00277647\n",
      "[76]\tvalid_0's binary_logloss: 0.00276912\n",
      "[77]\tvalid_0's binary_logloss: 0.00276156\n",
      "[78]\tvalid_0's binary_logloss: 0.00275742\n",
      "[79]\tvalid_0's binary_logloss: 0.00275569\n",
      "[80]\tvalid_0's binary_logloss: 0.0027561\n",
      "[81]\tvalid_0's binary_logloss: 0.00275924\n",
      "[82]\tvalid_0's binary_logloss: 0.00276383\n",
      "[83]\tvalid_0's binary_logloss: 0.0027705\n",
      "[84]\tvalid_0's binary_logloss: 0.00277874\n",
      "[85]\tvalid_0's binary_logloss: 0.00278492\n",
      "[86]\tvalid_0's binary_logloss: 0.00280624\n",
      "[87]\tvalid_0's binary_logloss: 0.00282722\n",
      "[88]\tvalid_0's binary_logloss: 0.0028387\n",
      "[89]\tvalid_0's binary_logloss: 0.00286282\n",
      "[90]\tvalid_0's binary_logloss: 0.00287887\n",
      "[91]\tvalid_0's binary_logloss: 0.00289407\n",
      "[92]\tvalid_0's binary_logloss: 0.00291215\n",
      "[93]\tvalid_0's binary_logloss: 0.00292622\n",
      "[94]\tvalid_0's binary_logloss: 0.00293965\n",
      "[95]\tvalid_0's binary_logloss: 0.00295995\n",
      "[96]\tvalid_0's binary_logloss: 0.00298265\n",
      "[97]\tvalid_0's binary_logloss: 0.00299963\n",
      "[98]\tvalid_0's binary_logloss: 0.00302258\n",
      "[99]\tvalid_0's binary_logloss: 0.00304132\n",
      "[100]\tvalid_0's binary_logloss: 0.00306016\n",
      "[101]\tvalid_0's binary_logloss: 0.00308246\n",
      "[102]\tvalid_0's binary_logloss: 0.00310259\n",
      "[103]\tvalid_0's binary_logloss: 0.0031305\n",
      "[104]\tvalid_0's binary_logloss: 0.00315426\n",
      "[105]\tvalid_0's binary_logloss: 0.00316615\n",
      "[106]\tvalid_0's binary_logloss: 0.0031865\n",
      "[107]\tvalid_0's binary_logloss: 0.0032153\n",
      "[108]\tvalid_0's binary_logloss: 0.00323469\n",
      "[109]\tvalid_0's binary_logloss: 0.0032508\n",
      "[110]\tvalid_0's binary_logloss: 0.00327585\n",
      "[111]\tvalid_0's binary_logloss: 0.00329945\n",
      "[112]\tvalid_0's binary_logloss: 0.00332497\n",
      "[113]\tvalid_0's binary_logloss: 0.00334405\n",
      "[114]\tvalid_0's binary_logloss: 0.00336519\n",
      "[115]\tvalid_0's binary_logloss: 0.00339769\n",
      "[116]\tvalid_0's binary_logloss: 0.00341976\n",
      "[117]\tvalid_0's binary_logloss: 0.00344166\n",
      "[118]\tvalid_0's binary_logloss: 0.00347004\n",
      "[119]\tvalid_0's binary_logloss: 0.00349485\n",
      "[120]\tvalid_0's binary_logloss: 0.00351608\n",
      "[121]\tvalid_0's binary_logloss: 0.00353979\n",
      "[122]\tvalid_0's binary_logloss: 0.00357188\n",
      "[123]\tvalid_0's binary_logloss: 0.00359874\n",
      "[124]\tvalid_0's binary_logloss: 0.00361936\n",
      "[125]\tvalid_0's binary_logloss: 0.0036459\n",
      "[126]\tvalid_0's binary_logloss: 0.00366765\n",
      "[127]\tvalid_0's binary_logloss: 0.00369945\n",
      "[128]\tvalid_0's binary_logloss: 0.00372218\n",
      "[129]\tvalid_0's binary_logloss: 0.00374091\n",
      "[130]\tvalid_0's binary_logloss: 0.00376806\n",
      "[131]\tvalid_0's binary_logloss: 0.00379414\n",
      "[132]\tvalid_0's binary_logloss: 0.0038181\n",
      "[133]\tvalid_0's binary_logloss: 0.00385137\n",
      "[134]\tvalid_0's binary_logloss: 0.00388477\n",
      "[135]\tvalid_0's binary_logloss: 0.00391012\n",
      "[136]\tvalid_0's binary_logloss: 0.00393097\n",
      "[137]\tvalid_0's binary_logloss: 0.00396084\n",
      "[138]\tvalid_0's binary_logloss: 0.00398246\n",
      "[139]\tvalid_0's binary_logloss: 0.00400676\n",
      "[140]\tvalid_0's binary_logloss: 0.00402987\n",
      "[141]\tvalid_0's binary_logloss: 0.00405542\n",
      "[142]\tvalid_0's binary_logloss: 0.00408316\n",
      "[143]\tvalid_0's binary_logloss: 0.0041042\n",
      "[144]\tvalid_0's binary_logloss: 0.00413107\n",
      "[145]\tvalid_0's binary_logloss: 0.00414964\n",
      "[146]\tvalid_0's binary_logloss: 0.00417669\n",
      "[147]\tvalid_0's binary_logloss: 0.004202\n",
      "[148]\tvalid_0's binary_logloss: 0.00421998\n",
      "[149]\tvalid_0's binary_logloss: 0.00424107\n",
      "[150]\tvalid_0's binary_logloss: 0.00425755\n",
      "[151]\tvalid_0's binary_logloss: 0.0042831\n",
      "[152]\tvalid_0's binary_logloss: 0.00430332\n",
      "[153]\tvalid_0's binary_logloss: 0.0043253\n",
      "[154]\tvalid_0's binary_logloss: 0.00434422\n",
      "[155]\tvalid_0's binary_logloss: 0.00436096\n",
      "[156]\tvalid_0's binary_logloss: 0.00437846\n",
      "[157]\tvalid_0's binary_logloss: 0.00440122\n",
      "[158]\tvalid_0's binary_logloss: 0.00442603\n",
      "[159]\tvalid_0's binary_logloss: 0.00444495\n",
      "[160]\tvalid_0's binary_logloss: 0.00445874\n",
      "[161]\tvalid_0's binary_logloss: 0.00446234\n",
      "[162]\tvalid_0's binary_logloss: 0.00448573\n",
      "[163]\tvalid_0's binary_logloss: 0.00449911\n",
      "[164]\tvalid_0's binary_logloss: 0.00450749\n",
      "[165]\tvalid_0's binary_logloss: 0.00452046\n",
      "[166]\tvalid_0's binary_logloss: 0.00452912\n",
      "[167]\tvalid_0's binary_logloss: 0.00454332\n",
      "[168]\tvalid_0's binary_logloss: 0.00455931\n",
      "[169]\tvalid_0's binary_logloss: 0.00457054\n",
      "[170]\tvalid_0's binary_logloss: 0.00458086\n",
      "[171]\tvalid_0's binary_logloss: 0.0045859\n",
      "[172]\tvalid_0's binary_logloss: 0.00459826\n",
      "[173]\tvalid_0's binary_logloss: 0.00460806\n",
      "[174]\tvalid_0's binary_logloss: 0.00461745\n",
      "[175]\tvalid_0's binary_logloss: 0.00463525\n",
      "[176]\tvalid_0's binary_logloss: 0.00464903\n",
      "[177]\tvalid_0's binary_logloss: 0.00466376\n",
      "[178]\tvalid_0's binary_logloss: 0.00467171\n",
      "[179]\tvalid_0's binary_logloss: 0.00468414\n",
      "혼동행렬 : \n",
      " [[85276     7]\n",
      " [   32   128]] \n",
      "정확도 : 0.9995, 정밀도 : 0.9481, 재현율 : 0.8000, f1_score : 0.8678, roc_auc : 0.9566\n"
     ]
    }
   ],
   "source": [
    "lgbm_score(LGBMClassifier,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Q2 신용카드 사기 검출 분류문제에서 아래를 참고하여 이상치 데이터를 제거하고 모델 학습/예측/평가를 수행하세요(5점)2.5\n",
    "- 히트맵을 이용해 레이블과의 상관성을 시각화 \n",
    "- 레이블과 상관성이 높은 피처를 위주로 이상치 검출하는 사용자 함수 생성\n",
    "- 사용자 함수를 이용하여 이상치 검출\n",
    "- 이상치 제거 사용자 함수를 이용하여 이상치 제거 후 로지스틱 회귀 및 LightGBM 수행 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. SMOTE 오버 샘플링 적용 후 LightGBM 모델을 이용하여 학습, 예측, 평가를 수행하세요.(10점)0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. 사이킷런에서 제공해주는 load_boston 데이터셋을 가져와서 아래 사항을 수행하세요.(10점)7.5\n",
    "- 데이터셋의 타겟 이름을 'PRICE'로 지정한 후 데이터프레임을 생성 pickle 파일로 저장 후 다시 불어오세요.\n",
    "- 히트맵을 이용하여 타겟과 상관관계가 높은 독립 변수를 선택하세요.\n",
    "- 종속변수를 로그 변환하세요\n",
    "- 위의 사항을 반영하여 선회회귀 모델을 생성 후 평가하고 회귀계수를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_r(y_test,y_pred):\n",
    "    mse = mean_squared_error(y_test,pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,pred)\n",
    "    print(f'mse : {mse}, rmse : {rmse}, r2_score = {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "dt_boston = pd.DataFrame(data=data.data,columns=data.feature_names)\n",
    "dt_boston['PRICE'] = data.target\n",
    "dt_boston.to_pickle('df_boston.pkl')\n",
    "dt_boston = pd.read_pickle('df_boston.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = abs(dt_boston.corr()['PRICE']).sort_values()\n",
    "corr\n",
    "# LSTAT이 가장 상관관계가 높음\n",
    "corr_list = ['LSTAT','RM','PTRATIO','INDUS','TAX','NOX','CRIM','RAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in corr_list:\n",
    "    dt_boston[i] = np.log1p(dt_boston[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse : 22.90005366375451, rmse : 4.785400052634524, r2_score = 0.7166819952083142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-7.83578619e-01,  1.29761670e-02, -1.49893583e-01,  8.11800078e-01,\n",
       "       -1.82092594e+01,  2.04147942e+01,  2.74593936e-02, -1.17203777e+00,\n",
       "        2.66279721e+00, -3.65209147e+00, -1.63408906e+01,  3.65588222e-03,\n",
       "       -1.06672191e+01])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "lr = LinearRegression()\n",
    "X = dt_boston.drop('PRICE',axis =1)\n",
    "y = dt_boston['PRICE']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 123)\n",
    "lr.fit(X_train,y_train)\n",
    "pred = lr.predict(X_test)\n",
    "score_r(y_test,pred)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. house_df.pkl 데이터셋을 불러와서 아래사항을 수행하세요.(15점) 10\n",
    "- alphas = [0, 0.1, 1, 10, 100] 를 적용하여 Ridge 회귀 모델링 및 교차 검증 수행 후 5 폴드 평균 RMSE 출력 \n",
    "- lasso_alphas = [0.07,0.1,0.5,1,3] 를 적용, Lasso 회귀 모델링 및 교차 검증 수행 후 5 폴드 평균 RMSE 출력(def get_linear_reg_eval(model_name,params=None,X_data_n=None, y_target_n=None, verbose=True 사용자 함수 이용) \n",
    "- elastic_alphas = [0.07,0.1,0.5,1,3] 를 적용, ElasticNet 회귀 모델링 및 교차검증 후 5 폴드 평균 RMSE를 출력(사용자 함수 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df = pd.read_pickle('./dataset/house_df.pkl')\n",
    "house_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_df.drop('PRICE',axis=1)\n",
    "y = house_df['PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha :  0\n",
      "6.093587405436876\n",
      "alpha :  0.1\n",
      "6.0761106775700435\n",
      "alpha :  1\n",
      "6.030267081364914\n",
      "alpha :  10\n",
      "5.967415344755178\n",
      "alpha :  100\n",
      "5.8676543967752846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet\n",
    "from sklearn.model_selection import cross_val_score\n",
    "alphas = [0, 0.1, 1, 10, 100]\n",
    "lasso_alphas = [0.07,0.1,0.5,1,3]\n",
    "elastic_alphas = [0.07,0.1,0.5,1,3]\n",
    "rmse_list = []\n",
    "for i in alphas:\n",
    "    ridge = Ridge(alpha=i)\n",
    "    score = cross_val_score(ridge,X,y,scoring='neg_mean_squared_error',cv=5)\n",
    "    rmse_list.append(np.sqrt(-1*score.mean()))\n",
    "    print('alpha : ', i)\n",
    "    print(np.mean(rmse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha :  0.07\n",
      "5.907231325847088\n",
      "alpha :  0.1\n",
      "5.9044813121103505\n",
      "alpha :  0.5\n",
      "5.898013011177185\n",
      "alpha :  1\n",
      "5.913719060391647\n",
      "alpha :  3\n",
      "6.0055156363797835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# lasso_alphas = [0.07,0.1,0.5,1,3] 를 적용, Lasso 회귀 모델링 및 교차 검증 수행 후 5 폴드 평균 RMSE 출력\n",
    "# (def get_linear_reg_eval(model_name,params=None,X_data_n=None, y_target_n=None, verbose=True 사용자 함수 이용) \n",
    "def get_linear_reg_eval(model_name,params=None,X_data_n=None, y_target_n=None, verbose=True):\n",
    "    rmse_list = []\n",
    "    for i in params:\n",
    "        clf = model_name(alpha = i)\n",
    "        score = cross_val_score(clf,X_data_n,y_target_n,scoring='neg_mean_squared_error',cv=5,verbose = verbose)\n",
    "        rmse_list.append(np.sqrt(-1*score.mean()))\n",
    "        print('alpha : ', i)\n",
    "        print(np.mean(rmse_list))\n",
    "get_linear_reg_eval(Lasso,lasso_alphas,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha :  0.07\n",
      "5.746594668577731\n",
      "alpha :  0.1\n",
      "5.724713027648879\n",
      "alpha :  0.5\n",
      "5.667484785929898\n",
      "alpha :  1\n",
      "5.666013042042827\n",
      "alpha :  3\n",
      "5.757869445644106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "get_linear_reg_eval(ElasticNet,elastic_alphas,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. load_boston 데이터셋을 불러와서 다음사항을 수행하세요.0\n",
    "- SVM 알고리즘을 활용한 주택가격 예측모델 생성 및 평가(MSE, RMSE, R2)\n",
    "- 개발된 예측모델을 활용하여 아래 test_data가 주어졌은때의 주택가격 예측<br>\n",
    "test_data = [3.7, 0, 18.4, 1, 0.87, 5.95, 91, 2.5052, 26, 666, 20.2, 351.34, 15.27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. mtcars 데이터셋(mtcars.csv)의 qsec 컬럼을 최소최대 척도(Min-Max Scale)로 변환한 후 0.5보다 \n",
    "큰 값을 가지는 레코드 수를 구하시오 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    9\n",
       "mpg           9\n",
       "cyl           9\n",
       "disp          9\n",
       "hp            9\n",
       "drat          9\n",
       "wt            9\n",
       "qsec          9\n",
       "vs            9\n",
       "am            9\n",
       "gear          9\n",
       "carb          9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "mtcars = pd.read_csv('./dataset/mtcars.csv')\n",
    "mtcars['qsec'] = scaler.fit_transform(mtcars[['qsec']])\n",
    "mtcars.loc[mtcars.qsec>0.5].count()\n",
    "# 9개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. purdata.csv는 백화점 고객의 1년 간 구매 데이터이다. 아래사항을 수행하세요.10\n",
    " \n",
    "- 남성고객을 분류하는 모델을 생성(분류알고리즘 : dt,rf,lr)\n",
    "- 모델 성능을 roc_auc로 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>총구매액</th>\n",
       "      <th>최대구매액</th>\n",
       "      <th>환불금액</th>\n",
       "      <th>주구매상품</th>\n",
       "      <th>주구매지점</th>\n",
       "      <th>내점일수</th>\n",
       "      <th>내점당구매건수</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>구매주기</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68282840</td>\n",
       "      <td>11264000</td>\n",
       "      <td>6860000.0</td>\n",
       "      <td>기타</td>\n",
       "      <td>강남점</td>\n",
       "      <td>19</td>\n",
       "      <td>3.894737</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>2136000</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>스포츠</td>\n",
       "      <td>잠실점</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3197000</td>\n",
       "      <td>1639000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>남성 캐주얼</td>\n",
       "      <td>관악점</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>*</td>\n",
       "      <td>4935000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기타</td>\n",
       "      <td>광주점</td>\n",
       "      <td>18</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>29050000</td>\n",
       "      <td>24000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>보석</td>\n",
       "      <td>본  점</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id      총구매액     최대구매액       환불금액   주구매상품 주구매지점  내점일수   내점당구매건수  \\\n",
       "0        0  68282840  11264000  6860000.0      기타   강남점    19  3.894737   \n",
       "1        1         *   2136000   300000.0     스포츠   잠실점     2  1.500000   \n",
       "2        2   3197000   1639000        NaN  남성 캐주얼   관악점     2  2.000000   \n",
       "3        3         *   4935000        NaN      기타   광주점    18  2.444444   \n",
       "4        4  29050000  24000000        NaN      보석  본  점     2  1.500000   \n",
       "\n",
       "     주말방문비율  구매주기  gender  \n",
       "0  0.527027    17       0  \n",
       "1  0.000000     1       0  \n",
       "2  0.000000     1       1  \n",
       "3  0.318182    16       1  \n",
       "4  0.000000    85       0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purdata = pd.read_csv('./dataset/purdata.csv')\n",
    "purdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catmax(X,c1,c2,c3):\n",
    "    cat = ''                #여기에 저장됨\n",
    "    if X < c1 : cat = 1\n",
    "    elif X < c2: cat = 2\n",
    "    elif X < c3: cat = 3\n",
    "    else:\n",
    "        cat = 4\n",
    "    return cat\n",
    "def get_cat(df,column):\n",
    "    c = df[column]\n",
    "    c1 = np.percentile(c,25)\n",
    "    c2 = np.percentile(c,50)\n",
    "    c3 = np.percentile(c,75)\n",
    "    df[column] = df[column].apply(lambda X : get_catmax(X,c1,c2,c3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        68282840.0\n",
       "2         3197000.0\n",
       "4        29050000.0\n",
       "5        11379000.0\n",
       "6        10056000.0\n",
       "           ...     \n",
       "3495      3175200.0\n",
       "3496     29628600.0\n",
       "3497        75000.0\n",
       "3498      1875000.0\n",
       "3499    263101550.0\n",
       "Name: 총구매액, Length: 3498, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purdata['총구매액'].replace('*',np.nan ,inplace=True)\n",
    "purdata.dropna(subset='총구매액',inplace=True)\n",
    "purdata.drop('cust_id',axis=1,inplace=True)\n",
    "purdata.총구매액.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>총구매액</th>\n",
       "      <th>최대구매액</th>\n",
       "      <th>환불금액</th>\n",
       "      <th>주구매상품</th>\n",
       "      <th>주구매지점</th>\n",
       "      <th>내점일수</th>\n",
       "      <th>내점당구매건수</th>\n",
       "      <th>주말방문비율</th>\n",
       "      <th>구매주기</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68282840</td>\n",
       "      <td>11264000</td>\n",
       "      <td>6860000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>3.894737</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3197000</td>\n",
       "      <td>1639000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29050000</td>\n",
       "      <td>24000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11379000</td>\n",
       "      <td>9552000</td>\n",
       "      <td>462000.0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10056000</td>\n",
       "      <td>7612000</td>\n",
       "      <td>4582000.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       총구매액     최대구매액       환불금액  주구매상품  주구매지점  내점일수   내점당구매건수    주말방문비율  \\\n",
       "0  68282840  11264000  6860000.0      5      0    19  3.894737  0.527027   \n",
       "2   3197000   1639000        NaN      6      1     2  2.000000  0.000000   \n",
       "4  29050000  24000000        NaN     15      8     2  1.500000  0.000000   \n",
       "5  11379000   9552000   462000.0     11     18     3  1.666667  0.200000   \n",
       "6  10056000   7612000  4582000.0     22      0     5  2.400000  0.333333   \n",
       "\n",
       "   구매주기  gender  \n",
       "0    17       0  \n",
       "2     1       1  \n",
       "4    85       0  \n",
       "5    42       0  \n",
       "6    42       0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "purdata['주구매상품'] = le.fit_transform(purdata['주구매상품'])\n",
    "purdata['주구매지점'] = le.fit_transform(purdata['주구매지점'])\n",
    "\n",
    "purdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "purdata.환불금액.fillna(0,inplace = True)\n",
    "purdata['환불금액'] = np.where(purdata.환불금액 == 0 ,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cat(purdata,'최대구매액')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelscores(model,X_train,X_test,y_train,y_test):\n",
    "    model.fit(X_train,y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    pred_proba = model.predict_proba(X_test)[:,1]\n",
    "    con = confusion_matrix(y_test,pred)\n",
    "    acc = accuracy_score(y_test,pred)\n",
    "    pre = precision_score(y_test,pred)\n",
    "    rec = recall_score(y_test,pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    roc = roc_auc_score(y_test,pred_proba)\n",
    "    print(f'모델 : {model} \\n혼동행렬 : \\n {con} \\n정확도 : {acc:0.4f}, 정밀도 : {pre:0.4f}, 재현율 : {rec:0.4f}, f1_score : {f1:0.4f}, roc_auc : {roc:0.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 : DecisionTreeClassifier() \n",
      "혼동행렬 : \n",
      " [[266 170]\n",
      " [150 114]] \n",
      "정확도 : 0.5429, 정밀도 : 0.4014, 재현율 : 0.4318, f1_score : 0.4161, roc_auc : 0.5210\n",
      "\n",
      "모델 : RandomForestClassifier() \n",
      "혼동행렬 : \n",
      " [[340  96]\n",
      " [167  97]] \n",
      "정확도 : 0.6243, 정밀도 : 0.5026, 재현율 : 0.3674, f1_score : 0.4245, roc_auc : 0.6168\n",
      "\n",
      "모델 : LogisticRegression() \n",
      "혼동행렬 : \n",
      " [[435   1]\n",
      " [264   0]] \n",
      "정확도 : 0.6214, 정밀도 : 0.0000, 재현율 : 0.0000, f1_score : 0.0000, roc_auc : 0.6191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "lr = LogisticRegression()\n",
    "X_train,X_test,y_train,y_test = train_test_split(purdata.drop('gender',axis=1),purdata['gender'],test_size=0.2,random_state=123)\n",
    "modelscores(dt,X_train,X_test,y_train,y_test)\n",
    "modelscores(rf,X_train,X_test,y_train,y_test)\n",
    "modelscores(lr,X_train,X_test,y_train,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
