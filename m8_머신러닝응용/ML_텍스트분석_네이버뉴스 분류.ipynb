{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[과제] https://news.naver.com/ 사이트에서 4개의 뉴스 카테고리를 선택해서 뉴스기사를 크롤링 한 후 다음을 수행하세요.\n",
    "\n",
    "- 뉴스기사 카테고리별 저장(파일 or DB)\n",
    "- 텍스트 전처리 및 피처 벡터화\n",
    "- 모델링 및 평가(성능개선 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import konlpy\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드라이버 경로\n",
    "path = 'C:/Users/kpo01/tool/chromedriver.exe'\n",
    "# 브라우저 창을 띄우지 말고 수행하도록 옵션 지정\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument('headless') \n",
    "# driver = webdriver.Chrome(path, options=options)\n",
    "driver = webdriver.Chrome(path)\n",
    "\n",
    "news_df = pd.DataFrame(columns = ['text','category']) # text, category 컬럼으로 이루어진 df 생성\n",
    "cat_list = ['101', '102', '103', '105'] # 경제, 사회, 생활/문화, IT/과학\n",
    "\n",
    "for cat in cat_list:\n",
    "    for page in range(1,25):\n",
    "        url = f'https://news.naver.com/main/main.naver?mode=LSD&mid=shm&sid1={cat}#&date=%2000:00:00&page={page}'\n",
    "        driver.get(url)\n",
    "        print('현재위치: ', driver.current_url) # 진행 현황 확인\n",
    "\n",
    "        # 헤드라인 기사 제목 클릭해서 기사 본문으로 들어가기\n",
    "        for i in range(1,5): \n",
    "            sleep(3)\n",
    "            for j in range(1,6): \n",
    "                try: \n",
    "                    print(i, j)\n",
    "                    driver.find_element(By.XPATH, f'//*[@id=\"section_body\"]/ul[{i}]/li[{j}]/dl/dt[2]/a').click()\n",
    "                    sleep(0.7)\n",
    "                    # 본문 수집(개행문자 제거)\n",
    "                    text = driver.find_element(By.XPATH, '//*[@id=\"articleBodyContents\"]').text.replace('\\n', '')\n",
    "                    # 데이터프레임에 본문과 카테고리를 행으로 삽입\n",
    "                    news_df.loc[len(news_df)] = [text, cat]\n",
    "                    # 뒤로 가기\n",
    "                    driver.back()\n",
    "                    sleep(0.7)\n",
    "                except:\n",
    "                    print(i, j)\n",
    "                    driver.find_element(By.XPATH, f'//*[@id=\"section_body\"]/ul[{i}]/li[{j}]/dl/dt/a').click()\n",
    "                    sleep(0.7)\n",
    "                    # 본문 수집(개행문자 제거)\n",
    "                    text = driver.find_element(By.XPATH, '//*[@id=\"articleBodyContents\"]').text.replace('\\n', '')\n",
    "                    # 데이터프레임에 본문과 카테고리를 행으로 삽입\n",
    "                    news_df.loc[len(news_df)] = [text, cat]\n",
    "                    # 뒤로 가기\n",
    "                    driver.back()\n",
    "                    sleep(0.7)\n",
    "            \n",
    "\n",
    "display(news_df)\n",
    "\n",
    "# CSV파일로 저장하기\n",
    "news_df.to_csv('./news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "news_df = pd.read_csv('./news.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102    480\n",
       "103    480\n",
       "105    480\n",
       "101    479\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = news_df['text']\n",
    "y = news_df['category']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from  sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def okt_tokenizer(text):\n",
    "    tokens_ko = okt.morphs(text)\n",
    "    return tokens_ko\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(tokenizer = okt_tokenizer, ngram_range = (1, 2), min_df = 3, max_df = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect.fit(X_train)\n",
    "tfidf_matrix_train = tfidf_vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10.5} 0.8163\n"
     ]
    }
   ],
   "source": [
    "lg_clf = LogisticRegression(random_state=0)\n",
    "\n",
    "params = {'C':[10,10.5,12]}\n",
    "\n",
    "grid_cv = GridSearchCV(lg_clf,param_grid=params,cv=3,scoring='accuracy')\n",
    "grid_cv.fit(tfidf_matrix_train,y_train)\n",
    "print(grid_cv.best_params_,round(grid_cv.best_score_,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 정확도: 0.8489583333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 학습 데이터를 적용한 TfidfVectorizer를 이용해 테스트 데이터를 TF-IDF값으로 피처 변환함.\n",
    "tfidf_matrix_test = tfidf_vect.transform(X_test)\n",
    "\n",
    "# Classifier는 GridSearchCV에서 최적 파라미터로 학습된 classifier를 그대로 이용\n",
    "preds = grid_cv.best_estimator_.predict(tfidf_matrix_test)\n",
    "\n",
    "print(f'Logistic Regression 정확도: {accuracy_score(y_test,preds)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05ac694886adde9125cb438ca1952c2124abc484b1a085dccba0cab67f4c2657"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('cakd5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
