{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_NER.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[],"mount_file_id":"1r1u0NqdaR2cyF1iJzsI5am1MBjuzb_1K","authorship_tag":"ABX9TyPMhrg+irWMNdhjKqprQfOX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["# 필요한 모듈 임포트\n","!pip install sacremoses\n","!pip install transformers\n","!pip install sentencepiece\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from transformers import *\n","import json\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import os\n","import re\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoR495t7fyeH","executionInfo":{"status":"ok","timestamp":1652663922654,"user_tz":-540,"elapsed":24741,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"a4580f50-c416-4ece-c48e-0606a0b90be7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[?25l\r\u001b[K     |▍                               | 10 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 757 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 768 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 778 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 788 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 798 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 808 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 819 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 829 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 839 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 849 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 860 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 870 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 880 kB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.1.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=145fe5bad241af905fc371345aad399dab798aaa784498a5aa7370f590c3ac9a\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: sacremoses\n","Successfully installed sacremoses-0.0.53\n","Collecting transformers\n","  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 77.5 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n","\u001b[K     |████████████████████████████████| 84 kB 2.9 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 67.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.1\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}]},{"cell_type":"code","source":["# 데이터 가져오기\n","# 이 데이터는 토큰화가 이미 완료되어 있음\n","dataset_folder_path = '/content/drive/MyDrive/Colab_Notebooks/2nd_project/dataset'\n","with open(f'{dataset_folder_path}/seq.in','r') as f:\n","    x_data = f.readlines()\n","with open(f'{dataset_folder_path}/seq.out','r') as f:\n","    y_data = f.readlines()"],"metadata":{"id":"5AdBXuR-269c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x = []\n","train_y = []\n","for i in x_data:\n","  train_x.append(re.sub('\\n','',i))\n","for j in y_data:\n","  train_y.append(re.sub('\\n','',j))"],"metadata":{"id":"ujh5y88g2-fn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x[33]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ds-yxHOBmgds","executionInfo":{"status":"ok","timestamp":1652667502528,"user_tz":-540,"elapsed":272,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"6c5c9cff-8a1c-4f25-ac1a-20c6fca2f3f5"},"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'상 큼 하며_ 와 인으로_ 무 겁 지_ 않은_ 느낌 을_ 주는_ 샴 페이 ᆫ _ 추 천_'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["train_y[33]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"lKZBjBEFmlRf","executionInfo":{"status":"ok","timestamp":1652666559854,"user_tz":-540,"elapsed":250,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"e0e75c11-306f-4ec8-df22-a9eeb3c6626e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'산미 산미 산미 O O 바디감 바디감 바디감 바디감 O O O 종류 종류 종류 종류 O O'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["# 라벨을 숫자로 딕셔너리형태로 저장\n","labels = ['O', '금액', '당도', '바디감', '산미', '종류']\n","label_dict = {word:i for i, word in enumerate(labels)}\n","label_dict.update({\"[PAD]\":len(label_dict)})\n","index_to_ner = {i:j for j, i in label_dict.items()}"],"metadata":{"id":"nPnSHQQYRVE4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# [토큰,라벨] 형태로 가공\n","data = []\n","tmp = []\n","for i,j in zip(train_x,train_y):\n","  tmp = []\n","  for a,b in zip(i.split(),j.split()):\n","    tmp.append([a,label_dict[b]])\n","  data.append(tmp)"],"metadata":{"id":"qetIcsu3STNF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[32:34]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FYMp-egLU7d6","executionInfo":{"status":"ok","timestamp":1652663925334,"user_tz":-540,"elapsed":4,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"e9408a53-2655-42f6-b874-935843a29ede"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[['안_', 4],\n","  ['신_', 4],\n","  ['10', 1],\n","  ['만원_', 1],\n","  ['이하_', 1],\n","  ['취', 0],\n","  ['하지_', 0],\n","  ['않', 0],\n","  ['게_', 0],\n","  ['기', 0],\n","  ['분', 0],\n","  ['만_', 0],\n","  ['낼_', 0],\n","  ['수_', 0],\n","  ['있는_', 0],\n","  ['와', 0],\n","  ['인_', 0],\n","  ['추', 0],\n","  ['천', 0],\n","  ['해', 0],\n","  ['줘', 0],\n","  ['_', 0]],\n"," [['상', 4],\n","  ['큼', 4],\n","  ['하며_', 4],\n","  ['와', 0],\n","  ['인으로_', 0],\n","  ['무', 3],\n","  ['겁', 3],\n","  ['지_', 3],\n","  ['않은_', 3],\n","  ['느낌', 0],\n","  ['을_', 0],\n","  ['주는_', 0],\n","  ['샴', 5],\n","  ['페이', 5],\n","  ['ᆫ', 5],\n","  ['_', 5],\n","  ['추', 0],\n","  ['천_', 0]]]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# 토큰 앞에 [CLS], 끝에 [SEP]추가 및 태그에 ['O']에 맞는 라벨 추가\n","sentences = []\n","targets = []\n","for tup in data:\n","  sentence = []\n","  target = []\n","  sentence.append(\"[CLS]\")\n","  target.append(label_dict['O'])\n","  for i, j in tup:\n","    sentence.append(i)\n","    target.append(j)\n","  sentence.append(\"[SEP]\")\n","  target.append(label_dict['O'])\n","  sentences.append(sentence)\n","  targets.append(target)"],"metadata":{"id":"eQRDzD3BVDCH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences[33]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00aN4Bl3VJQN","executionInfo":{"status":"ok","timestamp":1652663925743,"user_tz":-540,"elapsed":4,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"f8545172-4a1a-4181-b7fb-7e4d6d61a57d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS]',\n"," '상',\n"," '큼',\n"," '하며_',\n"," '와',\n"," '인으로_',\n"," '무',\n"," '겁',\n"," '지_',\n"," '않은_',\n"," '느낌',\n"," '을_',\n"," '주는_',\n"," '샴',\n"," '페이',\n"," 'ᆫ',\n"," '_',\n"," '추',\n"," '천_',\n"," '[SEP]']"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["targets[33]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brvxY9vRVLHN","executionInfo":{"status":"ok","timestamp":1652663925743,"user_tz":-540,"elapsed":3,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"8730a120-3ba0-4a2e-e63b-793befa19ab6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 4, 4, 4, 0, 0, 3, 3, 3, 3, 0, 0, 0, 5, 5, 5, 5, 0, 0, 0]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# 패딩을 위해 가장 긴 값 추출\n","print(max(np.array([len(x) for x in sentences])))\n","max_len = 41\n","bs = 32"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0dcTEirVkvj","executionInfo":{"status":"ok","timestamp":1652666922223,"user_tz":-540,"elapsed":239,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"cf3d378c-56bb-4ef9-812b-8dbffb95e75f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["41\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyns6iPec2iy","executionInfo":{"status":"ok","timestamp":1652666947991,"user_tz":-540,"elapsed":1289,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"a045e14b-b156-490f-bda7-32c739bb9aaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n"]}]},{"cell_type":"code","source":["# input_ids : 문장이 토크나이즈 된 것이 숫자로 바뀐 것\n","input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in sentences],\n","                          maxlen=max_len, dtype = \"int\", value=tokenizer.convert_tokens_to_ids(\"[PAD]\"), truncating=\"post\", padding=\"post\")"],"metadata":{"id":"2AScvvSNVmEq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_ids[33]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dGmHoTMydQpC","executionInfo":{"status":"ok","timestamp":1652664506056,"user_tz":-540,"elapsed":2,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"83f5040b-ddfb-4dbb-a84a-8c6e0c316f0b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 101, 9414, 9837,  100, 9590,  100, 9294, 8869,  100,  100,  100,\n","        100,  100,  100,  100,  100,  168, 9765,  100,  102,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0])"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# 패딩에 해당하는 부분은 label_dict([PAD]) (6)이 들어가게 되겠습니다.\n","tags = pad_sequences([lab for lab in targets], maxlen=max_len, value=label_dict[\"[PAD]\"], padding='post',\n","                     dtype='int', truncating='post')"],"metadata":{"id":"qGARxnI9VoEG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tags[33]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3iugQhg2ddo1","executionInfo":{"status":"ok","timestamp":1652664507524,"user_tz":-540,"elapsed":2,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"64aefefc-3844-44a3-efcc-1ed53846cc79"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 4, 4, 4, 0, 0, 3, 3, 3, 3, 0, 0, 0, 5, 5, 5, 5, 0, 0, 0, 6, 6,\n","       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n","       6, 6, 6, 6, 6, 6])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# attention_masks : 문장이 토크나이즈 된 것 중에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 마스킹\n","attention_masks = np.array([[int(i != tokenizer.convert_tokens_to_ids(\"[PAD]\")) for i in ii] for ii in input_ids])"],"metadata":{"id":"M2RMqyoCVpk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attention_masks[33]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8SYWfISeGq5","executionInfo":{"status":"ok","timestamp":1652664512017,"user_tz":-540,"elapsed":6,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"41410b23-7cad-43e0-af26-f60caa6ab6b7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["# train 데이터에서 10% 만큼을 validation 데이터로 분리\n","tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n","                                                            random_state=2018, test_size=0.1)"],"metadata":{"id":"PQrZYHIGVqyL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n","                                             random_state=2018, test_size=0.1)"],"metadata":{"id":"ZwWdbb1OVtjb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TPU 작동을 위해 실행\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cuJJKPYmVusP","executionInfo":{"status":"ok","timestamp":1652664528189,"user_tz":-540,"elapsed":16176,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"315b53ab-8e11-4dab-893f-96852baf8836"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:TPU system grpc://10.41.176.162:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:TPU system grpc://10.41.176.162:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.41.176.162:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.41.176.162:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.tpu.topology.Topology at 0x7fddb5eee450>"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["SEQ_LEN = max_len\n","def create_model():\n","  model = TFBertModel.from_pretrained(\"bert-base-multilingual-cased\", from_pt=True, num_labels=len(label_dict), output_attentions = False,\n","    output_hidden_states = False)\n","\n","  token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids') # 토큰 인풋\n","  mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks') # 마스크 인풋\n","\n","  bert_outputs = model([token_inputs, mask_inputs])\n","  bert_outputs = bert_outputs[0] # shape : (Batch_size, max_len, 30(개체의 총 개수))\n","  nr = tf.keras.layers.Dense(30, activation='softmax')(bert_outputs) # shape : (Batch_size, max_len, 30)\n","  \n","  nr_model = tf.keras.Model([token_inputs, mask_inputs], nr)\n","  \n","  nr_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00002), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","      metrics=['sparse_categorical_accuracy'])\n","  nr_model.summary()\n","  return nr_model"],"metadata":{"id":"fXlVWbjLVwEV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","# TPU를 활용하기 위해 context로 묶어주기\n","with strategy.scope():\n","  nr_model = create_model()\n","  nr_model.fit([tr_inputs, tr_masks], tr_tags, validation_data=([val_inputs, val_masks], val_tags), epochs=3, shuffle=False, batch_size=bs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mayzn5ILVxw1","executionInfo":{"status":"ok","timestamp":1652664913563,"user_tz":-540,"elapsed":385389,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"44fe9ef7-8f0d-440f-fe0d-e2699283530f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n","loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n","Loading PyTorch weights from /root/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n","PyTorch checkpoint contains 270,378,749 parameters\n","Loaded 177,853,440 parameters in the TF 2.0 model.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_word_ids (InputLayer)    [(None, 50)]         0           []                               \n","                                                                                                  \n"," input_masks (InputLayer)       [(None, 50)]         0           []                               \n","                                                                                                  \n"," tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  177853440   ['input_word_ids[0][0]',         \n","                                thPoolingAndCrossAt               'input_masks[0][0]']            \n","                                tentions(last_hidde                                               \n","                                n_state=(None, 50,                                                \n","                                768),                                                             \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," dense_1 (Dense)                (None, 50, 30)       23070       ['tf_bert_model_1[0][0]']        \n","                                                                                                  \n","==================================================================================================\n","Total params: 177,876,510\n","Trainable params: 177,876,510\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"]},{"output_type":"stream","name":"stdout","text":["1125/1125 [==============================] - 157s 81ms/step - loss: 0.0590 - sparse_categorical_accuracy: 0.9820 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 0.9991\n","Epoch 2/3\n","1125/1125 [==============================] - 86s 76ms/step - loss: 0.0032 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0012 - val_sparse_categorical_accuracy: 0.9995\n","Epoch 3/3\n","1125/1125 [==============================] - 86s 76ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.0011 - val_sparse_categorical_accuracy: 0.9995\n"]}]},{"cell_type":"code","source":["nr_model.save('/content/drive/MyDrive/Colab_Notebooks/m10_딥러닝응용/dataset')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"id":"hu7ATtPmqO28","executionInfo":{"status":"error","timestamp":1652667592839,"user_tz":-540,"elapsed":51820,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"4336a5cd-9f5f-40ae-9a67-ce5d1699a695"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 420). These functions will not be directly callable after loading.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/m10_딥러닝응용/dataset/assets\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Assets written to: /content/drive/MyDrive/Colab_Notebooks/m10_딥러닝응용/dataset/assets\n"]},{"output_type":"error","ename":"UnimplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-0761c7b5ec6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnr_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab_Notebooks/m10_딥러닝응용/dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36msync_executors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \"\"\"\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m       \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ContextSyncExecutors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Context is not initialized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnimplementedError\u001b[0m: File system scheme '[local]' not implemented (file: '/content/drive/MyDrive/Colab_Notebooks/m10_딥러닝응용/dataset/variables/variables_temp/part-00000-of-00001')\n\tEncountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors."]}]},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score, classification_report"],"metadata":{"id":"63xeqNS5V0jp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_predicted = nr_model.predict([val_inputs, val_masks])"],"metadata":{"id":"G1_5irmwV1kI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["f_label = [i for i, j in label_dict.items()]\n","val_tags_l = [index_to_ner[x] for x in np.ravel(val_tags).astype(int).tolist()]\n","y_predicted_l = [index_to_ner[x] for x in np.ravel(np.argmax(y_predicted, axis=2)).astype(int).tolist()]\n","f_label.remove(\"[PAD]\")"],"metadata":{"id":"6ZKlZgIcV2dt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print(classification_report(val_tags_l, y_predicted_l, labels=f_label))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"um96B2R_V3fp","executionInfo":{"status":"ok","timestamp":1652664923250,"user_tz":-540,"elapsed":2153,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"4047839b-771e-4aa1-8994-9cc642d5e980"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00     53946\n","          금액       1.00      1.00      1.00      7543\n","          당도       1.00      1.00      1.00      9184\n","         바디감       0.99      1.00      1.00      9031\n","          산미       1.00      1.00      1.00      8420\n","          종류       1.00      1.00      1.00      6934\n","\n","   micro avg       1.00      1.00      1.00     95058\n","   macro avg       1.00      1.00      1.00     95058\n","weighted avg       1.00      1.00      1.00     95058\n","\n"]}]},{"cell_type":"code","source":["def ner_inference(test_sentence):\n","  \n","\n","  tokenized_sentence = np.array([tokenizer.encode(test_sentence, max_length=max_len, truncation=True, padding='max_length')])\n","  tokenized_mask = np.array([[int(x!=1) for x in tokenized_sentence[0].tolist()]])\n","  ans = nr_model.predict([tokenized_sentence, tokenized_mask])\n","  ans = np.argmax(ans, axis=2)\n","\n","  tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence[0])\n","  new_tokens, new_labels = [], []\n","  for token, label_idx in zip(tokens, ans[0]):\n","    if (token.startswith(\"##\")):\n","      new_labels.append(index_to_ner[label_idx])\n","      new_tokens.append(token[2:])\n","    elif (token=='[CLS]'):\n","      pass\n","    elif (token=='[SEP]'):\n","      pass\n","    elif (token=='[PAD]'):\n","      pass\n","    elif (token != '[CLS]' or token != '[SEP]'):\n","      new_tokens.append(token)\n","      new_labels.append(index_to_ner[label_idx])\n","\n","  for token, label in zip(new_tokens, new_labels):\n","      print(\"{}\\t{}\".format(label, token))"],"metadata":{"id":"kyqWA_E4V4wA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ner_inference(\"달달한 레드와인 10만원으로 추천해줄래?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2MDs_WgqXCgW","executionInfo":{"status":"ok","timestamp":1652664932499,"user_tz":-540,"elapsed":9252,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"3a9477ab-98c9-4677-c365-e8c11fd335c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["당도\t달\n","당도\t달\n","당도\t한\n","종류\t레\n","종류\t드\n","O\t와\n","O\t인\n","금액\t10\n","금액\t만\n","금액\t원으로\n","O\t추\n","O\t천\n","O\t해\n","O\t줄\n","O\t래\n","O\t?\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"tvpDXemDXDKo"},"execution_count":null,"outputs":[]}]}