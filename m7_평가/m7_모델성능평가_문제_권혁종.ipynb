{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 기반 빅데이터 서비스 솔루션 개발 전문 과정\n",
    "\n",
    "#### 교과목명 : 모델 성능 평가\n",
    "- 평가일 : 03.13\n",
    "- 성명 : 권혁종\n",
    "- 점수 : 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. iris data를 불러와서 붓꽃의 종류를 분류하는 모델링을 수행한 후 오차행렬과 정확도를 평가하세요.\n",
    "- test_size = 0.2, 분류기는 DecisionTreeClassifier를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼동행렬 : \n",
      " [[13  0  0]\n",
      " [ 0  6  0]\n",
      " [ 0  1 10]] \n",
      "정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "X_train,X_test,y_train,y_test = train_test_split(data.data,data.target,test_size=0.2,random_state=123)\n",
    "dt.fit(X_train,y_train)\n",
    "pred=dt.predict(X_test)\n",
    "pred_proba=dt.predict_proba(X_test)\n",
    "con = confusion_matrix(y_test,pred)\n",
    "acc = accuracy_score(y_test,pred)\n",
    "print(f'혼동행렬 : \\n {con} \\n정확도 : {acc:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. 타이타닉 분석용 데이터세트인 tdf1.pkl를 불러와서 생존자 예측 모델을 만든 후 오차행렬, 정확도, 재현율, f1, AUC를 포함하는 사용자 함수를 활용하여 평가하세요.\n",
    "- test_size = 0.2, 분류기는 RandomForestClassifier 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
    "def scores(y_test,pred=None,pred_proba=None):\n",
    "    con = confusion_matrix(y_test,pred)\n",
    "    acc = accuracy_score(y_test,pred)\n",
    "    pre = precision_score(y_test,pred)\n",
    "    rec = recall_score(y_test,pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    roc = roc_auc_score(y_test,pred_proba)\n",
    "    print(f'혼동행렬 : \\n {con} \\n정확도 : {acc:0.4f}, 정밀도 : {pre:0.4f}, 재현율 : {rec:0.4f}, f1_score : {f1:0.4f}, roc_auc : {roc:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼동행렬 : \n",
      " [[102  13]\n",
      " [ 21  43]] \n",
      "정확도 : 0.8101, 정밀도 : 0.7679, 재현율 : 0.6719, f1_score : 0.7167, roc_auc : 0.8358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "data = pd.read_pickle('./dataset/tdf1.pkl')\n",
    "X = data.drop('Survived',axis=1)\n",
    "y = data['Survived']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=23)\n",
    "rf = RandomForestClassifier(random_state=25)\n",
    "rf.fit(X_train,y_train)\n",
    "pred = rf.predict(X_test)\n",
    "pred_proba = rf.predict_proba(X_test)[:,1]\n",
    "scores(y_test,pred,pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Q2에서 생성한 모델로 교차검증(cv=5)을 수행하고 평균 정확도를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7991023790094784"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score = cross_val_score(dt,X,y,cv=5,scoring='accuracy')\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Q2에서 생성한 예측모델에 대하여 교차 검증 및 성능 개선을 수행하세요.(GridSearchCV 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8212290502793296"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'max_depth' : [2,5,10],\n",
    "    'min_samples_leaf' : [2,4,7]\n",
    "}\n",
    "grid = GridSearchCV(dt,param_grid=params,scoring='accuracy',cv=3,refit=True)\n",
    "grid.fit(X_train,y_train)\n",
    "pred = grid.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5 ~ Q7. 'dataset/diabetes.csv'을 불러와서 아래사항을 수행하세요.10\n",
    "- 피마 인디언 당뇨병 예측을 로지스틱 회귀를 이용하여 수행하고 사용자 함수를 작성하여 평가(오차행렬, 정확도, 정밀도, 재현율, F1, ROC_AUC)\n",
    "- 임곗값을 0.3에서 0.5까지 변화시키면서 정밀도와 재현율이 조정되는 과정을 시각화 \n",
    "- 재현율 기준의 성능을 개선하기 위하여 그 값이 0이 될 수 없는 각 칼럼을 탐색하여 적절한 처리를 한 후 로지스틱 회귀로 예측 및 평가 수행(오차행렬, 정확도, 정밀도, 재현율, F1, ROC_AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "혼동행렬 : \n",
      " [[93  8]\n",
      " [18 35]] \n",
      "정확도 : 0.8312, 정밀도 : 0.8140, 재현율 : 0.6604, f1_score : 0.7292, roc_auc : 0.8670\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "data = pd.read_csv('./dataset/diabetes.csv')\n",
    "lr = LogisticRegression()\n",
    "X = data.drop('Outcome',axis=1)\n",
    "y = data['Outcome']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=23)\n",
    "lr.fit(X_train,y_train)\n",
    "pred = lr.predict(X_test)\n",
    "pred_proba = lr.predict_proba(X_test)[:,1]\n",
    "scores(y_test,pred,pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. \"dataset/auto-mpg.xlsx\"을 불러와서 회귀 모델을 생성하고 MSE, RMSE, R2로 평가를 수행하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 12.62161417303934 , rmse = 3.5526911170321775 , r2_score = 0.7356060087557543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import numpy as np\n",
    "mpg = pd.read_excel('./dataset/auto-mpg.xlsx')\n",
    "mpg.drop('car name',axis=1,inplace=True)\n",
    "mpg.horsepower.replace('?',np.nan,inplace=True)\n",
    "mpg.dropna(subset='horsepower',inplace=True)\n",
    "X = mpg.drop('mpg',axis=1)\n",
    "y = mpg['mpg']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=23)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "pred = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test,pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test,pred)\n",
    "print(f'mse = {mse} , rmse = {rmse} , r2_score = {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. 'load_boston' 을 불러와서 cross_val_score를 이용한 cv=5인 교차검증을 수행 후 MSE, RMSE를 출력하세요.(LineaRegression) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 mse = 37.13180746769902, 평균 rmse = 6.093587405436884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "data = load_boston()\n",
    "lr = LinearRegression()\n",
    "score = cross_val_score(lr,data.data,data.target,cv=5,scoring='neg_mean_squared_error')\n",
    "print(f'평균 mse = {-1*score.mean()}, 평균 rmse = {np.sqrt(-1*score.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. 'Q9에 대하여 R2 Score를 구하세요.(k=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
