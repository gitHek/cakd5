{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"one_hot_encoding.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM4V1VJIn0T+Nn4SzWHQbOD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["- 원-핫 인코딩은 토큰을 벡터로 변환하는 가장 일반적이고 기본적인 방법입니다. \n","- 모든 단어에 고유한 정수 인덱스를 부여하고 이 정수 인덱스 i를 크기가 N(어휘 사전의 크기)인 이진 벡터로 변환합니다. \n","- 이 벡터는 i번째 원소만 1이고 나머지는 모두 0입니다.\n","\n","- 물론 원-핫 인코딩은 문자 수준에서도 적용할 수 있습니다.\n"],"metadata":{"id":"UA_uUM1jWvcX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoXP3NZiWFap"},"outputs":[],"source":["import numpy as np\n","\n","# 초기 데이터: 각 원소가 샘플입니다\n","# (이 예에서 하나의 샘플이 하나의 문장입니다. 하지만 문서 전체가 될 수도 있습니다)\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","# 데이터에 있는 모든 토큰의 인덱스를 구축합니다\n","token_index = {}\n","for sample in samples:\n","    # split() 메서드를 사용해 샘플을 토큰으로 나눕니다.\n","    # 실전에서는 구둣점과 특수 문자도 사용합니다.\n","    for word in sample.split():\n","        if word not in token_index:\n","            # 단어마다 고유한 인덱스를 할당합니다.\n","            token_index[word] = len(token_index) + 1\n","            # 인덱스 0은 사용하지 않습니다.\n","\n","# 샘플을 벡터로 변환합니다.\n","# 각 샘플에서 max_length 까지 단어만 사용합니다.\n","max_length = 10\n","\n","# 결과를 저장할 배열입니다\n","results = np.zeros((len(samples), max_length, max(token_index.values()) + 1)) # 3차원 (2,10,11)\n","\n","for i, sample in enumerate(samples):\n","    for j, word in list(enumerate(sample.split()))[:max_length]:\n","        index = token_index.get(word)\n","        results[i, j, index] = 1."]},{"cell_type":"code","source":["results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnUm1_30Y0RJ","executionInfo":{"status":"ok","timestamp":1649811090166,"user_tz":-540,"elapsed":350,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"f97fd29c-9f5a-48a2-920b-025d5ef165d6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n","\n","       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["print(samples)\n","print(token_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L57WwJCXaLtX","executionInfo":{"status":"ok","timestamp":1649812322148,"user_tz":-540,"elapsed":352,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"665e9d2a-704b-4a21-959e-dd9add48a563"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['The cat sat on the mat.', 'The dog ate my homework.']\n","{'The': 1, 'cat': 2, 'sat': 3, 'on': 4, 'the': 5, 'mat.': 6, 'dog': 7, 'ate': 8, 'my': 9, 'homework.': 10}\n"]}]},{"cell_type":"code","source":["from keras.preprocessing.text import Tokenizer\n","\n","samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n","\n","# 가장 빈도가 높은 1,000개의 단어만 선택하도록 Tokenizer 객체를 만듭니다.\n","tokenizer = Tokenizer(num_words=10)\n","# 단어 인덱스를 구축합니다.\n","tokenizer.fit_on_texts(samples)\n","\n","# 문자열을 정수 인덱스의 리스트로 변환\n","sequences = tokenizer.texts_to_sequences(samples)\n","\n","# 원-핫 이진 벡터 표현 \n","one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n","\n","# 계산된 단어 인덱스를 구합니다.\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRKTJ0hFenPL","executionInfo":{"status":"ok","timestamp":1649812768357,"user_tz":-540,"elapsed":438,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"b919ee7b-4a07-43d4-8bc6-414d87533ae3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 9 unique tokens.\n"]}]},{"cell_type":"code","source":["print(word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0-AbtI_fqmj","executionInfo":{"status":"ok","timestamp":1649812769028,"user_tz":-540,"elapsed":10,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"c2e4d168-d239-4985-940b-8d5b2db96ff6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'the': 1, 'cat': 2, 'sat': 3, 'on': 4, 'mat': 5, 'dog': 6, 'ate': 7, 'my': 8, 'homework': 9}\n"]}]},{"cell_type":"code","source":["print(sequences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxZO-Kzdft0x","executionInfo":{"status":"ok","timestamp":1649812769029,"user_tz":-540,"elapsed":9,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"980d42c4-d96f-48ee-bc38-07c4a81f4333"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n"]}]},{"cell_type":"code","source":["print(one_hot_results[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJZKa08if1ui","executionInfo":{"status":"ok","timestamp":1649813069511,"user_tz":-540,"elapsed":571,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"fcbd0303-dd57-4b91-f939-2a831448ca3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 1. 0. 0. 0. 0. 1. 1. 1. 1.]\n"]}]},{"cell_type":"markdown","source":["[과제] 영어 5개 문장으로 구성된 텍스트를 가져와서 다음을 수행하세요.\n","- 수작업으로 벡터화\n","- Keras를 사용해 벡터화"],"metadata":{"id":"2wTYiAZogQR4"}},{"cell_type":"code","source":["texts = [\"What are you going to do on your trip to the Big Apple ?\", \"I myself have been to New York several times.\",\" Lots of things.\", \"We are going to eat a breakfast at the Embassy coffee shop.\", \" Besides we'll lunch and dinner at fancier places.\",\" Anyway, after breakfast we're going to go to the Metropolitan Museum of Art.\",\" Then we'ill take a bus across Central Park and go to the Museum of Natural History.\",\" Then we'll head downtown and go shopping.\"]\n"],"metadata":{"id":"2TuJFNEcWX6Q","executionInfo":{"status":"ok","timestamp":1649895011436,"user_tz":-540,"elapsed":375,"user":{"displayName":"권혁종","userId":"07484803130759059282"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# 수작업으로 벡터화\n","import numpy as np\n","\n","# 데이터에 있는 모든 토큰의 인덱스를 구축합니다\n","token_index = {}\n","for text in texts:\n","    # split() 메서드를 사용해 샘플을 토큰으로 나누기\n","    for word in text.split():\n","        if word not in token_index:\n","            # 단어마다 고유한 인덱스를 할당합니다.\n","            token_index[word] = len(token_index) + 1\n","            # 인덱스 0은 사용하지 않음\n","\n","# 샘플을 벡터로 변환합니다.\n","# 각 샘플에서 max_length 까지 단어만 사용합니다.\n","max_length = 30\n","\n","# 결과를 저장할 배열입니다\n","results = np.zeros((len(texts), max_length, max(token_index.values()) + 1)) # 3차원 (2,10,11)\n","\n","for i, text in enumerate(texts):\n","    for j, word in list(enumerate(text.split()))[:max_length]:\n","        index = token_index.get(word)\n","        results[i, j, index] = 1."],"metadata":{"id":"asQa3s2aWwuP","executionInfo":{"status":"ok","timestamp":1649895011782,"user_tz":-540,"elapsed":2,"user":{"displayName":"권혁종","userId":"07484803130759059282"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JYiRyKP4XJOo","executionInfo":{"status":"ok","timestamp":1649895012128,"user_tz":-540,"elapsed":3,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"7684de14-c92c-4904-b692-3e526665f5f6"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0., 1., 0., ..., 0., 0., 0.],\n","        [0., 0., 1., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       ...,\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]],\n","\n","       [[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 1., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["print(token_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZ4RcuFyXWzl","executionInfo":{"status":"ok","timestamp":1649895012525,"user_tz":-540,"elapsed":3,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"f848a5fd-56ed-406c-c717-3b4cd007da86"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["{'What': 1, 'are': 2, 'you': 3, 'going': 4, 'to': 5, 'do': 6, 'on': 7, 'your': 8, 'trip': 9, 'the': 10, 'Big': 11, 'Apple': 12, '?': 13, 'I': 14, 'myself': 15, 'have': 16, 'been': 17, 'New': 18, 'York': 19, 'several': 20, 'times.': 21, 'Lots': 22, 'of': 23, 'things.': 24, 'We': 25, 'eat': 26, 'a': 27, 'breakfast': 28, 'at': 29, 'Embassy': 30, 'coffee': 31, 'shop.': 32, 'Besides': 33, \"we'll\": 34, 'lunch': 35, 'and': 36, 'dinner': 37, 'fancier': 38, 'places.': 39, 'Anyway,': 40, 'after': 41, \"we're\": 42, 'go': 43, 'Metropolitan': 44, 'Museum': 45, 'Art.': 46, 'Then': 47, \"we'ill\": 48, 'take': 49, 'bus': 50, 'across': 51, 'Central': 52, 'Park': 53, 'Natural': 54, 'History.': 55, 'head': 56, 'downtown': 57, 'shopping.': 58}\n"]}]},{"cell_type":"code","source":["# keras 활용\n","from keras.preprocessing.text import Tokenizer\n","\n","# 가장 빈도가 높은 1,000개의 단어만 선택하도록 Tokenizer 객체를 만듭니다.\n","tokenizer = Tokenizer(num_words=1000)\n","# 단어 인덱스를 구축합니다.\n","tokenizer.fit_on_texts(texts)\n","\n","# 문자열을 정수 인덱스의 리스트로 변환\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","# 원-핫 이진 벡터 표현 \n","one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n","\n","# 계산된 단어 인덱스를 구합니다.\n","word_index = tokenizer.word_index\n","print('Found %s unique tokens.' % len(word_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XmSXrGP-XWxY","executionInfo":{"status":"ok","timestamp":1649895012842,"user_tz":-540,"elapsed":2,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"33287ab7-7c08-4166-dbea-436a653d887b"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 57 unique tokens.\n"]}]},{"cell_type":"code","source":["print(word_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QzjTfKfbYIpl","executionInfo":{"status":"ok","timestamp":1649895013177,"user_tz":-540,"elapsed":4,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"fce4dbe5-7ed9-471d-c707-83ba4433e1ea"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["{'to': 1, 'the': 2, 'going': 3, 'of': 4, 'and': 5, 'go': 6, 'are': 7, 'a': 8, 'breakfast': 9, 'at': 10, \"we'll\": 11, 'museum': 12, 'then': 13, 'what': 14, 'you': 15, 'do': 16, 'on': 17, 'your': 18, 'trip': 19, 'big': 20, 'apple': 21, 'i': 22, 'myself': 23, 'have': 24, 'been': 25, 'new': 26, 'york': 27, 'several': 28, 'times': 29, 'lots': 30, 'things': 31, 'we': 32, 'eat': 33, 'embassy': 34, 'coffee': 35, 'shop': 36, 'besides': 37, 'lunch': 38, 'dinner': 39, 'fancier': 40, 'places': 41, 'anyway': 42, 'after': 43, \"we're\": 44, 'metropolitan': 45, 'art': 46, \"we'ill\": 47, 'take': 48, 'bus': 49, 'across': 50, 'central': 51, 'park': 52, 'natural': 53, 'history': 54, 'head': 55, 'downtown': 56, 'shopping': 57}\n"]}]},{"cell_type":"code","source":["print(sequences)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lq_BaT8KYInh","executionInfo":{"status":"ok","timestamp":1649895013515,"user_tz":-540,"elapsed":3,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"70de6ad0-06cd-480a-ba7b-a4757551b988"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["[[14, 7, 15, 3, 1, 16, 17, 18, 19, 1, 2, 20, 21], [22, 23, 24, 25, 1, 26, 27, 28, 29], [30, 4, 31], [32, 7, 3, 1, 33, 8, 9, 10, 2, 34, 35, 36], [37, 11, 38, 5, 39, 10, 40, 41], [42, 43, 9, 44, 3, 1, 6, 1, 2, 45, 12, 4, 46], [13, 47, 48, 8, 49, 50, 51, 52, 5, 6, 1, 2, 12, 4, 53, 54], [13, 11, 55, 56, 5, 6, 57]]\n"]}]},{"cell_type":"code","source":["print(one_hot_results[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qg-a1srnYIkz","executionInfo":{"status":"ok","timestamp":1649895014569,"user_tz":-540,"elapsed":2,"user":{"displayName":"권혁종","userId":"07484803130759059282"}},"outputId":"0a56af83-edb2-489a-b0db-c41ba4f19456"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n"," 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"30VL1aXQYLBt"},"execution_count":null,"outputs":[]}]}